{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/term-frequency-and-weighting-1.html",
  "title": "Term frequency and weighting",
  "body": "\n\n\n\n\nTerm frequency and weighting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Inverse document frequency\n Up: Scoring, term weighting and\n Previous: The optimal weight g\n    Contents \n    Index\n\n\n\n\n \n \n\nTerm frequency and weighting\n \nThus far, scoring has hinged on whether or not a query term is present in a zone within a document. We take the next logical step: a document or zone that mentions a query term more often has more to do with that query and therefore should receive a higher score. To motivate this, we recall the notion of a  free text query  introduced in Section 1.4 : a query in which the terms of the query are typed freeform into the search interface, without any connecting search operators (such as Boolean operators). This query style, which is extremely popular on the web, views the query as simply a set of words. A plausible scoring mechanism then is to compute a score that is the sum, over the query terms, of the match scores between each query term and the document.\n\n\nTowards this end, we assign to each term in a document a weight for that term, that depends on the number of occurrences of the term in the document. We would like to compute a score between a query term  and a document , based on the weight of  in . The simplest approach is to assign the weight to be equal to the number of occurrences of term  in document . This weighting scheme is referred to as  term frequency  and is denoted  \n, with the subscripts denoting the term and the document in order.\n\n\n \nFor a document , the set of weights determined by the  weights above (or indeed any weighting function that maps the number of occurrences of  in  to a positive real value) may be viewed as a quantitative digest of that document. In this view of a document, known in the literature as the  bag of words model , the exact ordering of the terms in a document is ignored but the number of occurrences of each term is material (in contrast to Boolean retrieval). We only retain information on the number of occurrences of each term. Thus, the document ``Mary is quicker than John'' is, in this view, identical to the document ``John is quicker than Mary''. Nevertheless, it seems intuitive that two documents with similar bag of words representations are similar in content. We will develop this intuition further in Section 6.3 .\n\n\n\nBefore doing so we first study the question: are all words\nin a document equally important? Clearly not; in Section 2.2.2 (page ) we looked at the idea of stop words - words that we decide not to index at all, and therefore do not contribute in any way to retrieval and scoring.\n\n\n\n\nSubsections\n\nInverse document frequency\nTf-idf weighting\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Inverse document frequency\n Up: Scoring, term weighting and\n Previous: The optimal weight g\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}