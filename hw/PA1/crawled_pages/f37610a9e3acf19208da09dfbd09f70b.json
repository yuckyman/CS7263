{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/references-and-further-reading-16.html",
  "title": "References and further reading",
  "body": "\n\n\n\n\nReferences and further reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Exercises\n Up: Flat clustering\n Previous: Model-based clustering\n    Contents \n    Index\n\n\n\n\n \n\nReferences and further reading\n\n\nBerkhin (2006b) gives a general up-to-date survey of\nclustering methods with special attention to scalability.\nThe classic reference for clustering in pattern recognition,\ncovering both  -means and EM, is\n(Duda et al., 2000).  Rasmussen (1992) introduces\nclustering from an information retrieval perspective.\nAnderberg (1973) provides a general introduction to\nclustering for applications. In addition to  Euclidean\ndistance  and  cosine similarity ,\n Kullback-Leibler divergence  is often used in\nclustering as a\nmeasure of how (dis)similar documents and clusters are\n(Xu and Croft, 1999, Muresan and Harper, 2004, Kurland and Lee, 2004).\n\n\nThe cluster hypothesis is due to Jardine and van Rijsbergen (1971)\nwho state it as follows: Associations between\ndocuments convey information about the relevance of\ndocuments to requests.  \nCroft (1978), Can and Ozkarahan (1990), Voorhees (1985a), Salton (1975), Cacheda et al. (2003), Salton (1971a), Singitham et al. (2004), Can et al. (2004)\nand Altingövde et al. (2008)\ninvestigate the efficiency and effectiveness of\ncluster-based retrieval. While some of these studies show\nimprovements in effectiveness, efficiency or both, there is\nno consensus that cluster-based retrieval works well\nconsistently across scenarios.\nCluster-based language\nmodeling was pioneered by Liu and Croft (2004).\n\n\nThere is good evidence that clustering of search results\nimproves user experience and search result quality\n(Hearst and Pedersen, 1996, Zamir and Etzioni, 1999, Käki, 2005, Toda and Kataoka, 2005, Tombros et al., 2002), although not as much as search result\nstructuring based on carefully edited category hierarchies\n(Hearst, 2006).  The Scatter-Gather interface\nfor browsing collections was presented by\nCutting et al. (1992).  A theoretical framework for\nanalyzing the properties of Scatter/Gather and other\ninformation seeking user interfaces is presented by\nPirolli (2007).  Schütze and Silverstein (1997) evaluate LSI (Chapter 18 ) and\ntruncated representations of centroids for efficient  -means\nclustering.\n\n\nThe Columbia NewsBlaster system (McKeown et al., 2002), a\nforerunner to the now much more famous and refined Google\nNews (http://news.google.com), used hierarchical\nclustering (Chapter 17 ) to give two levels of news\ntopic granularity.  See Hatzivassiloglou et al. (2000)\nfor details, and\nChen and Lin (2000) and Radev et al. (2001) for related\nsystems.  Other applications of clustering in information\nretrieval are duplicate detection (Yang and Callan (2006),\nshingling), novelty detection (see references\nin hclstfurther) and  metadata \ndiscovery on the semantic web (Alonso et al., 2006).\n\n\nThe discussion of external evaluation measures is partially\nbased on Strehl (2002).\nDom (2002) proposes a measure  that is\nbetter motivated theoretically than NMI.  is the number\nof bits needed to transmit class memberships assuming\ncluster memberships are known.  The Rand index is due to\nRand (1971).  Hubert and Arabie (1985) propose an\n adjusted  that ranges between  and 1 and is 0 if there\nis only chance agreement between clusters and classes\n(similar to  in Chapter 8 ,\npage 8.2 ).  Basu et al. (2004) argue that the\nthree evaluation measures NMI, Rand index and F measure give\nvery similar results.  Stein et al. (2003) propose\n expected edge density  as\nan internal measure and give evidence that it is a good\npredictor of the quality of a clustering.\n\n\nKleinberg (2002) and\nMeila (2005) present axiomatic frameworks for\ncomparing clusterings.\n\n\nAuthors that are often credited with the invention of the\n -means algorithm include Lloyd (1982) (first\ndistributed in 1957), Ball (1965),\nMacQueen (1967), and Hartigan and Wong (1979).\nArthur and Vassilvitskii (2006) investigate the worst-case\ncomplexity of  -means. \nBradley and Fayyad (1998), Pelleg and Moore (1999) and\nDavidson and Satyanarayana (2003) investigate the convergence\nproperties \nof  -means empirically and how it depends on\ninitial seed selection.\nDhillon and Modha (2001) compare\n -means clusters with  SVD -based clusters (Chapter 18 ).  The\nK-medoid algorithm was presented by Kaufman and Rousseeuw (1990).\nThe EM algorithm was originally introduced by Dempster et al. (1977).\nAn in-depth treatment of EM is (McLachlan and Krishnan, 1996). See\nSection 18.5 (page ) for publications on latent analysis, which can\nalso be viewed as soft clustering.\n\n\nAIC is due to Akaike (1974) (see also\nBurnham and Anderson (2002)). An alternative to AIC is BIC, which\ncan be motivated as a Bayesian model selection procedure\n(Schwarz, 1978).  Fraley and Raftery (1998) show how to\nchoose an optimal number of clusters based on BIC. An\napplication of BIC to  -means is (Pelleg and Moore, 2000).\nHamerly and Elkan (2003) propose an alternative to BIC that\nperforms better in their experiments.  Another influential\nBayesian approach for determining the number of clusters\n(simultaneously with cluster assignment) is described by\nCheeseman and Stutz (1996).  Two methods for determining\ncardinality without external criteria are presented by\nTibshirani et al. (2001).\n\n\nWe only have space here for classical completely\nunsupervised clustering. An important current topic of\nresearch is how to use prior knowledge to guide clustering\n(e.g., Ji and Xu (2006)) and how to incorporate\ninteractive feedback during clustering (e.g.,\nHuang and Mitchell (2006)).  Fayyad et al. (1998) propose\nan initialization for EM clustering.  For algorithms that\ncan cluster very large data sets in one scan through the\ndata see Bradley et al. (1998).\n\n\nThe applications in Table 16.1  all cluster\ndocuments. Other information retrieval applications cluster\nwords (e.g., Crouch, 1988),  contexts of words\n(e.g., Schütze and Pedersen, 1995) or words and\ndocuments simultaneously\n(e.g., Tishby and Slonim, 2000, Zha et al., 2001, Dhillon, 2001).\nSimultaneous clustering of words and documents is an example\nof\n co-clustering  or  biclustering .\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Exercises\n Up: Flat clustering\n Previous: Model-based clustering\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}