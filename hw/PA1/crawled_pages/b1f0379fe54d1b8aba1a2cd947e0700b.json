{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/an-appraisal-of-probabilistic-models-1.html",
  "title": "An appraisal of probabilistic models",
  "body": "\n\n\n\n\nAn appraisal of probabilistic models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Tree-structured dependencies between terms\n Up: An appraisal and some\n Previous: An appraisal and some\n    Contents \n    Index\n\n\n\n\nAn appraisal of probabilistic models\n\n\nProbabilistic methods are one of the oldest formal models in IR. Already in the 1970s they were held out as an opportunity to place IR on a firmer theoretical footing, and with the resurgence of probabilistic methods in computational linguistics in the 1990s, that hope has returned, and probabilistic methods are again one of the currently hottest topics in IR.\nTraditionally, probabilistic IR has had neat ideas but the methods have never won on performance.  Getting reasonable approximations of the needed probabilities for a probabilistic IR model is possible, but it requires some major assumptions. In the BIM these are:\n\n\na Boolean representation of documents/queries/relevance\n\nterm independence\n\nterms not in the query don't affect the outcome\n\ndocument relevance values are independent\n\n\nIt is perhaps the severity of the modeling assumptions that makes achieving good performance difficult. A general problem seems to be that probabilistic models either require partial relevance information or else only allow for deriving apparently inferior term weighting models.\n\n\nThings started to change in the 1990s when the BM25 weighting scheme, which we discuss in the next section, showed very good performance, and started to be adopted as a term weighting scheme by many groups.  The difference between ``vector space'' and ``probabilistic'' IR systems is not that great: in either case, you build an information retrieval scheme in the exact same way that we discussed in Chapter 7 .  For a probabilistic IR system, it's just that, at the end, you score queries not by cosine similarity and tf-idf in a vector space, but by a slightly different formula motivated by probability theory. Indeed, sometimes people have changed an existing vector-space IR system into an effectively probabilistic system simply by adopted term weighting formulas from probabilistic models.  In this section, we briefly present three extensions of the traditional probabilistic model, and in the next chapter, we look at the somewhat different probabilistic language modeling approach to IR.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Tree-structured dependencies between terms\n Up: An appraisal and some\n Previous: An appraisal and some\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}