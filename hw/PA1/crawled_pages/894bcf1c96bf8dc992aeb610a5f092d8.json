{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/blocked-storage-1.html",
  "title": "Blocked storage",
  "body": "\n\n\n\n\nBlocked storage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Postings file compression\n Up: Dictionary compression\n Previous: Dictionary as a string\n    Contents \n    Index\n\n\n\n\nBlocked storage\n\nWe can further compress the dictionary by grouping terms\nin the string into    of size  and\nkeeping a term \npointer only for the first term of each block (Figure 5.5 ). We store the length of\nthe term in the string as an additional byte at\nthe beginning of the term. We thus eliminate  term\npointers, but need an additional  bytes for storing the\nlength of each term. For , we save\n\n bytes for term pointers, but need an\nadditional  bytes for term lengths. So the total space\nrequirements for the dictionary of Reuters-RCV1 are reduced by 5 bytes per\nfour-term block, or a total of \n, bringing us down to 10.37.1 MB. \n\n\n\n\nFigure 5.6:\n\nSearch of the uncompressed dictionary (a) and a\ndictionary compressed by blocking with  (b).\n\n\n\n\nBy increasing the block size , we get better compression.\nHowever, there is a tradeoff between compression and the speed of term lookup.  For the eight-term dictionary in\nFigure 5.6 , steps in binary search are shown as\ndouble lines and steps in list search as simple lines. We\nsearch for terms in the uncompressed dictionary by binary\nsearch (a). In the compressed dictionary, we first locate\nthe term's block by binary search and then its position\nwithin the list by linear search through the block (b).\nSearching the uncompressed dictionary in (a) takes on\naverage \n steps, assuming\neach term is equally likely to come up in a query.  For\nexample, finding the two terms, aid and\nbox, takes three and two steps, respectively.  With blocks\nof size  in (b), we need \n steps\non average, \n more.  For example, finding\nden takes one binary search step and two steps\nthrough the block.  By increasing , we can get the size of\nthe compressed dictionary arbitrarily close to the minimum\nof \n, but term lookup becomes\nprohibitively slow for large values of .\n\n\n\n\n\n\nOne source of redundancy in the dictionary we have not\nexploited yet is the fact that consecutive entries in an\nalphabetically sorted list share common prefixes.\nThis observation \nleads to \n front coding \n(Figure 5.7 ). A common prefix is identified for a\nsubsequence of the term list and then referred to with a special\ncharacter. In the case of Reuters,\nfront coding saves another 2.41.2 MB, as we found\nin an experiment.\n\n\nOther schemes with even greater compression rely on minimal perfect\nhashing, that is, a hash function that maps  terms onto\n without collisions.  However, we cannot adapt\nperfect hashes incrementally because each new term causes a\ncollision and therefore requires the creation of a new\nperfect hash function. Therefore, they cannot be used\nin a dynamic environment.\n\n\n Even with the best compression scheme, it may not be\nfeasible to store the entire dictionary in main memory for\nvery large text collections and for hardware with limited\nmemory. If we have to partition the dictionary onto pages\nthat are stored on disk, then we can index the first term of\neach page using a B-tree.  For processing most queries, the\nsearch system has to go to disk anyway to fetch the\npostings. One additional seek for retrieving the term's\ndictionary page from disk is a significant, but tolerable\nincrease in the time it takes to process a query.\n\n\n\n\n\n\n\nTable 5.2:\nDictionary compression for Reuters-RCV1.\n data structure\nsize in MB\n \n dictionary, fixed-width\n19.211.2\n \n dictionary, term pointers into string\n10.8 7.6\n \n , with blocking, \n10.3 7.1\n \n , with blocking & front coding\n7.9 5.9\n \n\n \n\n\nTable 5.2  summarizes the\ncompression achieved by the four dictionary data structures.\n\n\nExercises.\n\nEstimate the space usage of the Reuters-RCV1 dictionary\nwith blocks of size  and  in blocked dictionary\nstorage.\n\n\n\nEstimate the time needed for term lookup in\nthe compressed dictionary of Reuters-RCV1 with block sizes of  (Figure 5.6 , b), , and .\nWhat is the slowdown compared with  (Figure 5.6 , a)?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Postings file compression\n Up: Dictionary compression\n Previous: Dictionary as a string\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}