{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/choosing-a-document-unit-1.html",
  "title": "Choosing a document unit",
  "body": "\n\n\n\n\nChoosing a document unit\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Determining the vocabulary of\n Up: Document delineation and character\n Previous: Obtaining the character sequence\n    Contents \n    Index\n\n\n\n \n\nChoosing a document unit\n\n\nThe next phase is to determine what the \n document unit  for\nindexing is.  Thus far we have assumed that documents are fixed units for\nthe purposes of indexing.  For example, we take each file in a\nfolder as a document. But there are many cases in which you might want to do\nsomething different.  A traditional Unix (mbox-format) email file stores\na sequence of email messages (an email folder) in one file, but you might wish\nto regard each email message as a separate document.  Many email messages now\ncontain attached documents, and you might then want to regard the email\nmessage and each contained attachment as separate documents.  If an email\nmessage has an attached zip file, you might want to decode the zip file\nand regard each file it contains as a separate document.  \nGoing in the\nopposite direction, various pieces of web software (such as\nlatex2html) take things that you  \nmight regard as a single document (e.g., a Powerpoint file or a LATEX document) and split them into separate HTML pages for each slide or\nsubsection, stored as separate files.  In these cases, you might want to\ncombine multiple files into a single document.\n\n\nMore generally, for very long documents, the issue of indexing\n granularity  arises. \nFor a collection of books, it would usually\nbe a bad idea to index an entire book as a document. A search for\nChinese toys might bring up a book that mentions China in\nthe first chapter and toys in the last chapter, but this does not make\nit relevant to the query. \nInstead, we may well wish to\nindex each chapter or paragraph as a mini-document.\nMatches are then more likely to be relevant, and since the documents are\nsmaller it will be much easier for the user to find the relevant\npassages in the document.  \nBut why stop there?  We could treat individual sentences as\nmini-documents.  It becomes clear that there is a precisionrecall \ntradeoff here. If the units get too small, we are likely to\nmiss important passages because terms were distributed over\nseveral mini-documents, while if units are too large we tend to get\nspurious matches and the relevant information is hard for the user to find. \n\n\nThe problems with large document units can be alleviated by use of\nexplicit or implicit proximity search\n( and 7.2.2 ), and the tradeoffs in resulting\nsystem performance that we are hinting at are discussed in \nChapter 8 .  The issue of index\ngranularity, and in particular a need to simultaneously index documents\nat multiple levels of granularity, appears prominently in XML\nretrieval, and is taken up again in Chapter 10 .\nAn IR system should be designed to offer choices of granularity.\nFor this choice to be made well, the person who is deploying the system must\nhave a good understanding of the document collection, the users, and their \nlikely information needs and usage patterns.\nFor now, we will henceforth assume that a suitable size\ndocument unit has been chosen, together\nwith an appropriate way of dividing or aggregating files, if needed.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Determining the vocabulary of\n Up: Document delineation and character\n Previous: Obtaining the character sequence\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}