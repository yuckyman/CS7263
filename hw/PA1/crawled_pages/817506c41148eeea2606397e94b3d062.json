{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/experimental-results-1.html",
  "title": "Experimental results",
  "body": "\n\n\n\n\nExperimental results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Issues in the classification\n Up: Extensions to the SVM\n Previous: Nonlinear SVMs\n    Contents \n    Index\n\n\n\n \n\nExperimental results\n\n\n\n\n\n \n \nRoc-\nDec.\n \nlinear SVM\nrbf-SVM\n\n \nNB\nchio\nTrees\nkNN\n\n\n\n\n\nearn\n96.0\n96.1\n96.1\n97.8\n98.0\n98.2\n98.1\n\nacq\n90.7\n92.1\n85.3\n91.8\n95.5\n95.6\n94.7\n\nmoney-fx\n59.6\n67.6\n69.4\n75.4\n78.8\n78.5\n74.3\n\ngrain\n69.8\n79.5\n89.1\n82.6\n91.9\n93.1\n93.4\n\ncrude\n81.2\n81.5\n75.5\n85.8\n89.4\n89.4\n88.7\n\ntrade\n52.2\n77.4\n59.2\n77.9\n79.2\n79.2\n76.6\n\ninterest\n57.6\n72.5\n49.1\n76.7\n75.6\n74.8\n69.1\n\nship\n80.9\n83.1\n80.9\n79.8\n87.4\n86.5\n85.8\n\nwheat\n63.4\n79.4\n85.5\n72.9\n86.6\n86.8\n82.4\n\ncorn\n45.2\n62.2\n87.7\n71.4\n87.5\n87.8\n84.6\n\nmicroavg.\n72.3\n79.9\n79.4\n82.6\n86.7\n87.5\n86.4\n\n\nSVM classifier break-even F from (Joachims, 2002a, p. 114).\n Results are shown for the 10 largest categories and for microaveraged performance over all 90 categories on the Reuters-21578 data\n  set. \n\n\n\nWe presented results in Section 13.6  showing that\nan SVM is a very effective text classifier.\nThe results of Dumais et al. (1998) given in Table 13.9 \nshow SVMs clearly performing the best.\nThis was one of several pieces of \nwork from this time that established the strong reputation of SVMs for text\nclassification.  Another pioneering work on scaling and evaluating SVMs for\ntext classification was (Joachims, 1998).  We present some of his results from (Joachims, 2002a) in Table 15.2 .Joachims used a large number of term\nfeatures \nin contrast to Dumais et al. (1998),\nwho used MI feature selection (Section 13.5.1 ,\npage 13.5.1 )\nto build classifiers with a much more limited number of features.\nThe success of the linear SVM mirrors the results discussed\nin Section 14.6 (page )\non other linear approaches like Naive Bayes.  It seems that\nworking with simple term features can get one a long way.\nIt is again noticeable the extent to which different papers' results for\nthe same machine learning methods differ.\nIn particular, based on replications by other researchers, the Naive Bayes\nresults of (Joachims, 1998) appear too weak, and \nthe results in Table 13.9  should be taken as representative.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Issues in the classification\n Up: Extensions to the SVM\n Previous: Nonlinear SVMs\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}