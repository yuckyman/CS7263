{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/clustering-in-information-retrieval-1.html",
  "title": "Clustering in information retrieval",
  "body": "\n\n\n\n\nClustering in information retrieval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Problem statement\n Up: Flat clustering\n Previous: Flat clustering\n    Contents \n    Index\n\n\n\n\nClustering in information retrieval\n\nThe  cluster hypothesis  states\nthe fundamental assumption we make when using\nclustering in information retrieval.\n\nCluster hypothesis. Documents in the same cluster\nbehave similarly with respect to\nrelevance to information needs.\n\n\nThe hypothesis states that if there is a document from a\ncluster that is relevant to a search request, then it is\nlikely that other documents from the same cluster are also\nrelevant. This is because clustering puts \ntogether documents that share many terms. The\ncluster hypothesis essentially is \nthe contiguity hypothesis in Chapter 14 \n(page 14 ). In both cases, we posit that\nsimilar documents behave similarly with respect to\nrelevance.\n\n\n \n\n\n\nTable 16.1:\n\nSome applications of clustering in information\nretrieval.\n\nApplication\nWhat is\nBenefit\nExample\n\n \nclustered?\n \n \n\nSearch result clustering\nsearch results\nmore effective information\npresentation to user\nFigure 16.2\n\nScatter-Gather\n(subsets of) collection\nalternative\nuser interface: \n``search without typing''\nFigure 16.3\n\nCollection clustering\ncollection\neffective information\npresentation for exploratory browsing\nMcKeown et al. (2002),\nhttp://news.google.com\n\nLanguage modeling\ncollection\nincreased precision \nand/or recall\nLiu and Croft (2004)\n\nCluster-based retrieval\ncollection\nhigher\nefficiency: \nfaster search\nSalton (1971a)\n\n\n \n\n\n\n\n\nTable 16.1  shows some of the main applications of\nclustering in information retrieval. They differ in the set\nof documents that they cluster - search results, collection or\nsubsets of the collection - and the aspect of an information\nretrieval system they try to  improve - user experience, user\ninterface, effectiveness or efficiency of the\nsearch system. But they are all based on the basic\nassumption stated by the cluster hypothesis.\n\n\n\n\nClustering of search results to improve\nrecall. None of the top hits cover the animal sense of\njaguar, but users can easily access it by clicking on the\ncat cluster in the Clustered\nResults panel on the left (third arrow from the top).\n\n\n\n\nThe first application mentioned in Table 16.1  is\n search result\nclustering  where by  search\nresults  we mean the documents that were returned\nin response to a query.  The default presentation of search results\nin information retrieval is a simple list. Users scan the\nlist from top to bottom until they have found the\ninformation they are looking for. Instead, search result\nclustering clusters the search results, so that similar\ndocuments appear together. It is often easier to scan a few\ncoherent groups than many individual documents. This is\nparticularly useful if a search term has different word\nsenses. The example in Figure 16.2  is\njaguar. Three frequent senses on the web refer to the\ncar, the animal and an Apple operating system. The\nClustered Results panel returned by the\nVivísimo search engine (http://vivisimo.com) can\nbe a more effective user interface for understanding what is\nin the search results than a simple list of documents.\n\n\n\nAn example of \na user session in Scatter-Gather. A collection of New York\nTimes news stories is clustered (``scattered'') into eight\nclusters (top row). The user manually gathers three of these into a\nsmaller collection International Stories and performs another\nscattering operation. This process\nrepeats until a small cluster with relevant documents\nis found (e.g., Trinidad).\n\n\n\n\nA better user interface is also the goal of  Scatter-Gather , the second\napplication in Table 16.1 . Scatter-Gather clusters the whole\ncollection to get groups of documents that the user can\nselect or gather. The selected groups are merged and the\nresulting set is again clustered. This process is repeated\nuntil a cluster of interest is found. An example is shown in \nFigure 16.3 .\n\n\nAutomatically generated clusters like those in\nFigure 16.3  are not as neatly organized as a\nmanually constructed hierarchical tree like the Open\nDirectory at http://dmoz.org. Also, finding descriptive labels for clusters\nautomatically is a difficult problem\n(Section 17.7 , page 17.7 ). But\ncluster-based navigation is an interesting alternative to\nkeyword searching, the standard information retrieval\nparadigm. This is especially true in scenarios where users\nprefer browsing over searching because they are unsure about\nwhich search terms to use.\n\n\nAs an alternative to the user-mediated iterative clustering in Scatter-Gather,\nwe can also compute a static hierarchical\nclustering of a collection that is not influenced by user\ninteractions (``Collection clustering'' in Table 16.1 ). Google News and its precursor, the Columbia\nNewsBlaster system, are examples of this approach. In the\ncase of news, we need to frequently recompute the clustering\nto make sure that users can access the latest breaking\nstories. Clustering is well suited for access to a\ncollection of news stories since news reading is not really\nsearch, but rather a process of selecting a subset of\nstories about recent events.\n\n\nThe fourth application of clustering exploits the\ncluster hypothesis directly for improving search results,\nbased on a clustering of the entire collection.\nWe use a standard inverted index to\nidentify an initial set of documents that match the query,\nbut we then\nadd other documents from the same clusters even if they have\nlow similarity to the query.\nFor example, if the query is car and several car\ndocuments are taken from a cluster of automobile documents,\nthen we can add documents from this cluster\nthat use terms other than car (automobile,\nvehicle etc). This can increase\nrecall since a group of documents with high mutual\nsimilarity is often relevant as a whole.\n\n\nMore recently this idea has been used for\nlanguage modeling. \nEquation 102 ,  page 102 , showed that\nto avoid sparse data problems in the language modeling\napproach to IR, the \nmodel of document  can be interpolated with a collection model.\nBut the collection contains\nmany documents with terms untypical of . By\nreplacing the collection model with a model derived from\n's cluster, we get more accurate estimates of the occurrence\nprobabilities of terms in . \n\n\nClustering can also speed up search.  As we saw in\nSection 6.3.2 \n( page 6.3.2 )\nsearch in the vector space model amounts to finding the\nnearest neighbors to the query.  The inverted index supports\nfast nearest-neighbor search for the standard IR setting.\nHowever, sometimes we may not be able to use an inverted\nindex efficiently, e.g., in latent semantic indexing\n(Chapter 18 ). In such cases, we could compute the\nsimilarity of the query to every document, but this is\nslow. The cluster hypothesis offers an alternative: Find the\nclusters that are closest to the query and only consider\ndocuments from these clusters.  Within this much smaller\nset, we can compute similarities exhaustively and rank\ndocuments in the usual way.  Since there are many fewer\nclusters than documents, finding the closest cluster is\nfast; and since the documents matching a query are all\nsimilar to each other, they tend to be in the same clusters.\nWhile this algorithm is inexact, the expected decrease in\nsearch quality is small. This is essentially the application\nof clustering that was covered in Section 7.1.6 \n(page 7.1.6 ).\n\n\nExercises.\n\nDefine two documents as similar if they have at\nleast two proper names like Clinton or\nSarkozy in common.  Give an example of an\ninformation need and two documents, for which the cluster\nhypothesis does not hold for this notion of similarity.\n\n\n\nMake up a simple one-dimensional example (i.e. points on a line)\nwith two clusters where the inexactness of cluster-based\nretrieval shows up. In your example, retrieving clusters close to\nthe query should do worse than direct nearest neighbor search.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Problem statement\n Up: Flat clustering\n Previous: Flat clustering\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}