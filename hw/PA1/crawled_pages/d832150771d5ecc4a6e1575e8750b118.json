{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/dynamic-indexing-1.html",
  "title": "Dynamic indexing",
  "body": "\n\n\n\n\nDynamic indexing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Other types of indexes\n Up: Index construction\n Previous: Distributed indexing\n    Contents \n    Index\n\n\n\n\n \n\nDynamic indexing\n\n\nThus far, we have assumed that the document collection is\nstatic. This is fine for collections that change\ninfrequently or never (e.g., the Bible or Shakespeare).  But\nmost collections are modified frequently with documents being\nadded, deleted, and updated.  This means that new terms need\nto be added to the dictionary, and postings lists need to be\nupdated for existing terms.\n\n\nThe simplest way to achieve this is to periodically\nreconstruct the index from scratch. This is a good solution\nif the number of changes over time is small and a delay in\nmaking new documents searchable is acceptable - and if\nenough resources are available to construct a new index\nwhile the old one is still available for querying.\n\n\nIf there is a requirement that new documents be included\nquickly, one solution is to maintain two indexes: a large\nmain index and a small  auxiliary index  that stores\nnew documents. The auxiliary index is kept in\nmemory. Searches are run across both indexes and results\nmerged. Deletions are stored in an invalidation bit\nvector. We can then filter out deleted documents before\nreturning the search result. Documents are updated by\ndeleting and reinserting them.\n\n\nEach time the auxiliary index becomes too large, we merge it into\nthe main index. The cost of this merging operation depends\non  how we store the index in the file system. If we store\neach postings list as a separate file, then the merge simply\nconsists of extending each postings list of the main index by\nthe corresponding postings list of the auxiliary\nindex. In this scheme, \nthe reason for keeping the auxiliary\nindex is to reduce the number of disk seeks required over\ntime. Updating each document separately requires up to disk seeks, where  is the average size of the vocabulary of \ndocuments in the collection. With an auxiliary index, we only put additional load on\nthe disk when we merge auxiliary and main indexes.\n\n\nUnfortunately, the one-file-per-postings-list scheme is\ninfeasible because most file systems cannot efficiently\nhandle very large numbers of files. The simplest alternative\nis to store the index as one large file, that is, as a\nconcatenation of all postings lists. In reality, we\noften choose a compromise between the two extremes\n(Section 4.7 ). To simplify the discussion, we\nchoose the simple option of storing the index as one large\nfile here.\n\n\nIn this scheme, we process each posting \n times because we touch it during each of \n merges where  is the size of the auxiliary\nindex and  the total number of postings.  Thus, the\noverall time complexity is . (We neglect the\nrepresentation of terms here and consider only the\ndocIDs. For the purpose of time complexity, a postings list is simply a list of docIDs.)\n\n\n\n\nFigure:\nLogarithmic merging. Each token\n(termID,docID) is\ninitially added to in-memory index  by LMERGEADDTOKEN. \nLOGARITHMICMERGE initializes  and .\n\n\n\n\nWe can do better than  by introducing\n indexes , , , ...of\nsize , , \n.... Postings percolate up this sequence of indexes and\nare processed only once on each level.  This scheme is\ncalled  logarithmic merging  (Figure 4.7 ). As\nbefore, up to  postings are accumulated in an in-memory\nauxiliary index, which we call . When the limit  is reached,\nthe  postings in  are transferred to a\nnew index  that is created on disk.\nThe next time  is full, it is merged with \nto create an index  of size \n.  Then \nis either stored as  (if there isn't already an )\nor merged with  into  (if  exists); and so\non.  We service search requests by querying in-memory \nand all currently valid indexes  on disk and merging\nthe results. Readers familiar with the binomial\nheap data structure will\nrecognize its similarity  with the structure of the inverted\nindexes in logarithmic merging.\n\n\nOverall index construction time is \n\nbecause each posting is processed only once on each of the\n levels. We trade\nthis efficiency gain for a slow down of query processing;\nwe now need to merge results from  indexes as\nopposed to just two (the main and auxiliary indexes).  As in\nthe auxiliary index scheme, we still need to merge very\nlarge indexes occasionally (which slows down the search\nsystem during the merge), but this happens less\nfrequently and the indexes involved in a merge  on\naverage are smaller.\n\n\nHaving multiple indexes complicates the maintenance of\ncollection-wide  statistics.  For example, it affects the\nspelling correction algorithm in Section 3.3 (page ) that\nselects the corrected alternative with the most hits. With\nmultiple indexes and an invalidation bit vector, the correct\nnumber of hits for a term is no longer a simple lookup.  \nIn fact, all\naspects of an IR system - index maintenance, query\nprocessing, distribution, and so on - are more complex in logarithmic\nmerging.\n\n\nBecause of this complexity of dynamic indexing, some large\nsearch engines adopt a reconstruction-from-scratch\nstrategy.  They do not construct indexes\ndynamically. Instead, a new index is built from scratch\nperiodically. Query processing is then switched from the new\nindex and the old index is deleted.\n\n\nExercises.\n\nFor  and \n, perform a\nstep-by-step \nsimulation of the\nalgorithm in Figure 4.7 . \nCreate a table that shows,\nfor each point in time\nat which  tokens have been processed (\n), which of the three indexes \n\nare in use. The first three lines of the table are given below.\n\n\n  \n\n\n\n\n \n 2\n0\n0\n0\n0\n \n 4\n0\n0\n0\n1\n \n 6\n0\n0\n1\n0\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Other types of indexes\n Up: Index construction\n Previous: Distributed indexing\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}