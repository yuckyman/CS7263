{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/features-a-crawler-must-provide-1.html",
  "title": "Features a crawler must provide",
  "body": "\n\n\n\n\nFeatures a crawler must provide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Features a crawler should\n Up: Overview\n Previous: Overview\n    Contents \n    Index\n\n\n\n\n \n\nFeatures a crawler must provide\n \nWe list the desiderata for web crawlers in two categories: features that web crawlers must provide, followed by features they should provide.\n\nRobustness:\nThe Web contains servers that create spider\ntraps, which are generators of web pages that mislead crawlers\ninto getting stuck fetching an infinite number of pages in a\nparticular domain. Crawlers must be designed to be resilient to\nsuch traps. Not all such traps are malicious; some are the inadvertent side-effect of faulty website development.\n \n\nPoliteness:\nWeb servers have both implicit and explicit\npolicies regulating the rate at which a crawler can visit them.\nThese politeness policies must be respected.\n\n\n\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}