{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/the-url-frontier-1.html",
  "title": "The URL frontier",
  "body": "\n\n\n\n\nThe URL frontier\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Distributing indexes\n Up: Crawling\n Previous: DNS resolution\n    Contents \n    Index\n\n\n\n\n \n\nThe URL frontier\n \n The URL frontier at a node is given a URL by its crawl process (or by the host splitter of another crawl process). It maintains the URLs in the frontier and regurgitates them in some order whenever a crawler thread seeks a URL. Two important considerations govern the order in which URLs are returned by the frontier. First, high-quality pages that change frequently should be prioritized for frequent crawling. Thus, the priority of a page should be a function of both its change rate and its quality (using some reasonable quality estimate). The combination is necessary because a large number of spam pages change completely on every fetch.\n\n\nThe second consideration is politeness: we must avoid repeated fetch requests to a host within a short time span. The likelihood of this is exacerbated because of a form of locality of reference: many URLs link to other URLs at the same host. As a result, a URL frontier implemented as a simple priority queue might result in a burst of fetch requests to a host. This might occur even if we were to constrain the crawler so that at most one thread could fetch from any single host at any time. A common heuristic is to insert a gap between successive fetch requests to a host that is an order of magnitude larger than the time taken for the most recent fetch from that host.\n\n\n\n\n\n\nFigure 20.3  shows a polite and prioritizing\nimplementation of a URL frontier. Its goals are to ensure that (i) only one connection is open at a time to any host; (ii) a waiting time of a few seconds occurs between successive requests to a host and (iii) high-priority pages are crawled preferentially.\n\n\nThe two major sub-modules are a set of  front queues in the upper portion of the figure,\nand a set of  back queues in the lower part; all of these are FIFO queues. The front queues implement the prioritization, while the back queues implement politeness. In the flow of a URL added to the frontier as it makes its way through the front and back queues, a prioritizer first assigns to the URL an integer priority  between 1 and  based on its fetch history (taking into account the rate at which the web page at this URL has changed between previous crawls). For instance, a document that has exhibited frequent change would be assigned a higher priority. Other heuristics could be application-dependent and explicit - for instance, URLs from news services may always be assigned the highest priority. Now that it has been assigned priority , the URL is now appended to the th of the front queues.\n\n\nEach of the  back queues maintains the following invariants: (i) it is non-empty while the crawl is in progress and (ii) it only contains URLs from a single host. An auxiliary table  (Figure 20.4 ) is used to maintain the mapping from hosts to back queues. Whenever a back-queue is empty and is being re-filled from a front-queue, table  must be updated accordingly.\n\n\nIn addition, we maintain a heap with one entry for each back queue, the entry being the earliest time  at which the host corresponding to that queue can be contacted again.\n\n\n\n\nFigure 20.4:\nExample of an auxiliary hosts-to-back queues table.\n\n\n\n\nA crawler thread requesting a URL from the frontier extracts the\nroot of this heap and (if necessary) waits until the corresponding\ntime entry . It then takes the URL  at the head of the back\nqueue  corresponding to the extracted heap root, and proceeds to\nfetch the URL . After fetching , the calling thread checks\nwhether  is empty. If so, it picks a front queue and extracts\nfrom its head a URL . The choice of front queue is biased (usually by a random process) towards queues of higher priority, ensuring that URLs of high priority flow more quickly into the back queues. We examine  to check whether there is already a back queue holding URLs from its host. If so,  is added to that queue and we reach back to the front queues to find another candidate URL for insertion into the now-empty queue . This process continues until  is non-empty again. In any case, the thread inserts a heap entry for  with a new earliest time  based on the properties of the URL in  that was last fetched (such as when its host was last contacted as well as the time taken for the last fetch), then continues with its processing. For instance, the new entry  could be the current time plus ten times the last fetch time.\n\n\nThe number of front queues, together with the policy of assigning\npriorities and picking queues, determines the priority properties we wish to build into the system. The number of back queues governs\nthe extent to which we can keep all crawl threads busy while\nrespecting politeness. The designers of Mercator recommend a rough\nrule of three times as many back queues as crawler threads.\n\n\nOn a Web-scale crawl, the URL frontier may grow to the point where it\ndemands more memory at a node than is available. The solution is to\nlet most of the URL frontier reside on disk. A portion of each queue is kept in memory, with more brought in from disk as it is drained in memory.\n\n\nExercises.\n\nWhy is it better to partition hosts (rather than\nindividual URLs) between the nodes of a distributed crawl\nsystem?\n\n\n\nWhy should the host splitter precede the Duplicate\nURL Eliminator?\n\n\n\n In the\npreceding discussion we encountered two recommended ``hard\nconstants'' - the increment on  being ten\ntimes the last fetch time, and the number of back queues being\nthree times the number of crawl threads. How are\nthese two constants related?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Distributing indexes\n Up: Crawling\n Previous: DNS resolution\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}