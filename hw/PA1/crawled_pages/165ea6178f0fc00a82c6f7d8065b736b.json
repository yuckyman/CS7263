{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html",
  "title": "Inverse document frequency",
  "body": "\n\n\n\n\nInverse document frequency\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Tf-idf weighting\n Up: Term frequency and weighting\n Previous: Term frequency and weighting\n    Contents \n    Index\n\n\n\n\n \n\nInverse document frequency\n \nRaw term frequency as above suffers from a critical problem: all terms are considered equally important when it comes to assessing relevancy on a query. In fact certain terms have little or no discriminating power in determining relevance. For instance, a collection of documents on the auto industry is likely to have the term auto in almost every document. To this end, we introduce a mechanism for attenuating the effect of terms that occur too often in the collection to be meaningful for relevance determination. An immediate idea is to scale down the term weights of terms with high collection frequency, defined to be the total number of occurrences of a term in the collection. The idea would be to reduce the  weight of a term by a factor that grows with its collection frequency.\n\n\nInstead, it is more commonplace to use for this purpose the  document frequency  , defined to be the number of documents in the collection that contain a term .  This is because in trying to discriminate between documents for the purpose of scoring it is better to use a document-level statistic (such as the number of documents containing a term) than to use a collection-wide statistic for the term.\n\n\n\nFigure 6.7:\nCollection frequency (cf) and document frequency (df) behave differently, as in this example from the Reuters collection.\n\n\n\nThe reason to prefer df to cf is illustrated in Figure 6.7 , where a simple example shows that collection frequency (cf) and document frequency (df) can behave rather differently. In particular, the cf values for both try and insurance are roughly equal, but their df values differ significantly. Intuitively, we want the few documents that contain insurance to get a higher boost for a query on insurance than the many documents containing try get from a query on try.\n\n\nHow is the document frequency df of a term used to scale its weight? Denoting as usual the total number of documents in a collection by , we define the  inverse document frequency  of a term  as follows:\n\n\n\n\n\n\n\n\n(21)\n\n\n\nThus the idf of a rare term is high, whereas the idf of a\nfrequent term is likely to be low. Figure 6.8  gives\nan example of idf's in the Reuters collection of 806,791\ndocuments; in this example logarithms are to the base 10. In\nfact, as we will see in Exercise 6.2.2 , the precise\nbase of the logarithm is not material to ranking.  We will give\non page 11.3.3  a justification of the\nparticular form in Equation 21.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Tf-idf weighting\n Up: Term frequency and weighting\n Previous: Term frequency and weighting\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}