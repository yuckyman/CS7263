{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html",
  "title": "Dropping common terms: stop words",
  "body": "\n\n\n\n\nDropping common terms: stop words\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Normalization (equivalence classing of\n Up: Determining the vocabulary of\n Previous: Tokenization\n    Contents \n    Index\n\n\n\n\n \n\nDropping common terms: stop words\n\n\n\n\nFigure 2.5:\nA stop list of 25\n  semantically non-selective words which are common in Reuters-RCV1.\n\n\n\n\nSometimes, some extremely common words which would appear to be of little\nvalue in helping select documents matching a user need\nare excluded from the vocabulary entirely.  These words are called\n stop words .  The general strategy for\ndetermining a stop list is to sort the terms by  collection frequency \n(the total number of times each term appears in the document collection),\nand then to \ntake the most frequent terms, often hand-filtered for their semantic\ncontent relative to the domain of the documents being indexed, as a \n stop list , the members of which are\nthen discarded during indexing.  An example of a \nstop list is shown in Figure 2.5 . \nUsing a stop list significantly reduces the number of postings that a\nsystem has to store; we will present some statistics on this in\nChapter 5  (see Table 5.1 , page 5.1 ).\nAnd a lot of the time not indexing stop words does little harm: keyword\nsearches with terms like the \nand by don't seem very useful.\nHowever, this is not true for phrase searches. The phrase query\n``President of the United States'', which contains two stop words, is more\nprecise than President AND\n``United States''.  The meaning of flights to London is likely\nto be lost if the word to is stopped out.  A search for Vannevar\nBush's article As we may think will be difficult if the\nfirst three words are stopped out, and the system searches simply for\ndocuments containing the word think.\nSome special query\ntypes are disproportionately affected.  Some song titles and well known\npieces of verse consist entirely of words that are commonly on stop lists\n(To be or not to be, Let It Be,\nI don't want to be, ...). \n\n\nThe general trend in IR systems over time has been from standard use of\nquite large stop \nlists (200-300 terms) to very small stop lists (7-12 terms) to no stop\nlist whatsoever.  Web search engines generally do not use stop lists.  Some\nof the design of modern IR systems has focused precisely on how we can\nexploit the statistics of language so as to be able to cope with common\nwords in better ways.  We will show in Section 5.3 (page ) how good\ncompression techniques greatly reduce the cost of storing the postings\nfor common words.  idf then discusses how standard term weighting\nleads to very common words having little impact on document rankings. Finally,\nSection 7.1.5 (page ) shows how an IR\nsystem with impact-sorted indexes can terminate scanning a postings list\nearly when weights get small, and hence common words do not cause a large\nadditional processing cost for the average query, even though postings lists \nfor stop \nwords are very long.  So for most modern IR systems, the additional cost\nof including stop words is not that big - neither in terms of index\nsize nor in terms of query processing time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Normalization (equivalence classing of\n Up: Determining the vocabulary of\n Previous: Tokenization\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}