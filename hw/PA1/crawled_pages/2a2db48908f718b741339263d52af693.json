{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/the-bias-variance-tradeoff-1.html",
  "title": "The bias-variance tradeoff",
  "body": "\n\n\n\n\nThe bias-variance tradeoff\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: References and further reading\n Up: Vector space classification\n Previous: Classification with more than\n    Contents \n    Index\n\n\n\n\n \n\nThe bias-variance tradeoff\n\n\nNonlinear classifiers are more powerful than linear\nclassifiers. For some problems, there exists a nonlinear\nclassifier with zero classification error, but no such\nlinear classifier. Does that mean that we should always use nonlinear\nclassifiers for optimal effectiveness in statistical text\nclassification? \n\n\nTo answer this question, we introduce the bias-variance\ntradeoff in this section,\none of the most important concepts in machine\nlearning. The tradeoff helps explain why there is no universally\noptimal learning method. \nSelecting an appropriate learning method is therefore an\nunavoidable part of solving a text classification problem.\n\n\nThroughout this section, we use linear and nonlinear classifiers as\nprototypical examples of ``less powerful'' and ``more powerful''\nlearning, respectively. This is a simplification for\na number of reasons. First, many nonlinear models subsume\nlinear models as a special case. For instance, a nonlinear learning method like\nkNN will in some cases produce a linear classifier.\nSecond, there are nonlinear models that are less complex\nthan linear models. For instance, a quadratic polynomial\nwith two parameters\nis less powerful than a 10,000-dimensional linear classifier.\nThird, the complexity of learning is not really a property of\nthe classifier because there are many aspects of learning (such as\nfeature selection, cf. feature,\nregularization, and constraints such as margin\nmaximization in Chapter 15 )\nthat make a learning method either more powerful or less\npowerful without affecting the type of classifier that is\nthe final result of learning  - regardless of whether that\nclassifier is linear or nonlinear.\nWe refer the reader to the publications listed in Section 14.7 \nfor a treatment of the bias-variance tradeoff that takes\ninto account these complexities. In this section, linear\nand nonlinear classifiers will simply serve as proxies for weaker and stronger\nlearning methods in text classification.\n\n\nWe first need to state our objective in text classification\nmore precisely. In Section 13.1 (page ), we\nsaid that we want to minimize classification\nerror on the test set. The implicit assumption was that\ntraining documents and test documents are generated\naccording to\nthe same underlying\ndistribution. We will denote this distribution\t\n\n where  is the document and  its label or class.\ngraphclassmodelbernoulligraph were examples of\ngenerative models that decompose\n\n into the product of  and\n. \ntypicallineartypicalnonlinear depict generative\nmodels for \n\n with\n\n and \n.\n\n\nIn this section, instead of using the number of\ncorrectly classified test documents (or, equivalently, the\nerror rate on test documents) as evaluation measure, we\nadopt\nan evaluation measure that\naddresses the inherent uncertainty of labeling.  In\nmany text classification problems, a given document\nrepresentation can \narise from documents belonging to\ndifferent classes. This is\nbecause documents from different classes can be mapped to\nthe same document representation. For example, the\none-sentence documents China sues France and\nFrance sues China are mapped to the same\ndocument representation \n in a bag of\nwords model. But only the latter document is relevant to the\nclass  legal actions brought by France (which\nmight be defined, for example, as a standing query by an\ninternational trade lawyer).\n\n\nTo simplify the calculations in this section, we \ndo not count the number of errors on the test set\nwhen evaluating a classifier, but instead\nlook at how well\nthe classifier estimates the conditional probability \nof a document being in a class.  In the above example, we\nmight have \n. \n\n\nOur goal in text classification then is to find a classifier\n such that, averaged over documents ,\n is as close as possible to\nthe true probability .\nWe measure this using mean squared error:\n\n\n\n\n\n \n \n\n(148)\n\n\nwhere   is the expectation with respect to \n.\nThe mean squared error term gives partial\ncredit for decisions by  that are close if not completely right.\n\n\nWe define a classifier \nto be   optimal  for a distribution\n\n if it minimizes \n.\n\n\nMinimizing MSE is a desideratum for classifiers.\nWe also need a criterion for learning methods.  Recall that we defined a\nlearning method  as a function that takes a labeled\ntraining set \n as input and returns a\nclassifier .\n\n\nFor learning methods, we adopt\nas our goal \nto find a  that, averaged over training sets,\nlearns classifiers  with minimal MSE. We can\nformalize this as minimizing\n learning error :\n\n\n\n\n\n \n \n\n(149)\n\n\nwhere \n is the expectation over\nlabeled training sets. \nTo keep things simple, we can\nassume that training sets have a fixed\nsize - the distribution \n\nthen defines a distribution \n over\ntraining sets.\n\n\nWe can use learning error as\na criterion for selecting a\nlearning method in statistical text classification.\nA learning method  is\n optimal  for a distribution \n if it minimizes the\nlearning error.\n\n\n\n\n\n\n\n\n\n\n(150)\n \n\n\n\n(151)\n \n \n\n\n(152)\n \n\n\n\n(153)\n \n \n\n\n(154)\n \n\n\n\n(155)\n \n \n \n\n(156)\n\n\n\n\n(157)\n \n\n\n\n(158)\n \n \n\n\n(159)\n\n\nArithmetic transformations for the\nbias-variance decomposition.\nFor the derivation of Equation 157, \nwe set \n and \n in Equation 150.\n \n\nWriting\n\n for\n\n for better readability,\nwe can transform\nEquation 149  as follows:\n\n\n\n\n\n\n\n\n(160)\n \n\n\n\n(161)\n \n\n\n\n(162)\n\n\n\n\n(163)\n\n\n\n\n(164)\n\n\nwhere the equivalence between\n and 162 \nis shown in Equation 157 in Figure 14.6 .\nNote that  and \n are independent of\neach other. In general, for a random document  and\na random training set \n, \n does not contain a\nlabeled instance of .\n\n\n Bias  is the squared difference between\n, the true conditional probability of  being in\n, and \n, the prediction\nof the learned classifier, averaged over training\nsets.  Bias\nis large if the learning method produces classifiers that\nare consistently wrong. Bias is small if (i) the classifiers\nare consistently right or (ii) different training sets\ncause errors on different documents or (iii) different\ntraining sets cause positive and negative errors on the same\ndocuments, but that average out to close to 0. If one of these\nthree conditions holds,\nthen\n\n, the expectation over all\ntraining sets, is close to .\n\n\nLinear methods like Rocchio and Naive Bayes have a high bias\nfor nonlinear problems because they can only model one type\nof class boundary, a linear hyperplane. If the\n generative model \n has a\ncomplex nonlinear class boundary, the bias term in\nEquation 162 will be high because a large number of\npoints will be consistently misclassified.  For example, the\ncircular enclave in Figure 14.11  does not fit a\nlinear model and will be misclassified consistently by\nlinear classifiers.\n\n\nWe can think of bias as resulting from our domain knowledge\n(or lack thereof) that we build into the classifier.  If we\nknow that the true boundary between the two classes is\nlinear, then a learning method that produces linear\nclassifiers is more likely to succeed than a nonlinear\nmethod.  But if the true class boundary is not linear and we\nincorrectly bias the classifier to be linear, then\nclassification accuracy will be low on average.\n\n\nNonlinear methods like kNN have low bias.  We can see in\nFigure 14.6  that the decision boundaries of kNN\nare variable - depending on the distribution of documents\nin the training set, learned decision boundaries can vary\ngreatly.  As a result, each document has a chance of being\nclassified correctly for some training sets.  The average\nprediction \n\nis therefore closer to  and bias is smaller\nthan for a linear learning method.\n\n\n Variance  is the variation\nof the prediction of learned classifiers: the average\nsquared difference between \n and\nits average \n.\nVariance is large if different training sets\n\n give rise to very different classifiers\n\n.  It is small if the training set\nhas a minor effect on the classification decisions\n\n makes, be they correct or incorrect.\nVariance measures how inconsistent the decisions are, not\nwhether they are correct or incorrect.\n\n\nLinear learning methods have low variance because\nmost randomly drawn\ntraining sets produce similar decision hyperplanes.\nThe decision lines produced by linear learning methods in\n and 14.11  will deviate\nslightly from the main class boundaries, depending on the\ntraining set, but the class assignment for\nthe vast majority of documents  (with the exception of those close to\nthe main boundary) will not be affected. The circular enclave\nin Figure 14.11  will be consistently misclassified.\n\n\nNonlinear methods like kNN have high variance.  It is\napparent from Figure 14.6  that kNN can model very\ncomplex boundaries between two classes. It is therefore\nsensitive to noise documents of the sort depicted in\nFigure 14.10 .  As a result the variance term in\nEquation 162 is large for kNN: Test documents are sometimes\nmisclassified - if they happen to be close to a noise\ndocument in the training set - and sometimes correctly\nclassified - if there are no noise documents in the\ntraining set near them. This results in high variation from\ntraining set to training set.\n\n\nHigh-variance learning methods are prone to \n overfitting  the training data.\nThe goal in classification is to fit the training data to\nthe extent that we capture true properties of the underlying\ndistribution \n. In overfitting, the\nlearning method also learns from noise.  Overfitting increases\nMSE and frequently is a problem for\nhigh-variance learning methods.\n\n\nWe can also think of variance as the \n model complexity \nor, equivalently,  memory capacity \nof the learning method - how detailed a characterization of the\ntraining set it can remember and then apply to new\ndata. This capacity corresponds to\nthe number of\nindependent parameters available to fit the training set.\nEach kNN neighborhood  makes an\nindependent classification decision. The parameter in this\ncase is the estimate \n from\nFigure 14.7 . Thus, kNN's\ncapacity is only limited by the size of the training set. It can memorize arbitrarily large\ntraining sets. In contrast,\nthe number of parameters of Rocchio is fixed\n- \nparameters per dimension, one for each centroid - and\nindependent of the size of the training\nset. The Rocchio classifier (in form of the centroids\ndefining it) cannot ``remember'' fine-grained details of the\ndistribution of the documents in the training set.\n\n\nAccording to Equation 149, our goal in selecting a\nlearning method is to minimize learning error.  The\nfundamental insight captured by Equation 162, which\nwe can succinctly state as: learning-error = bias +\nvariance, is that the learning error has two components,\nbias and variance, which in general cannot be minimized\nsimultaneously.  When comparing two learning methods\n and , in most cases the comparison\ncomes down to one method having higher bias and lower\nvariance and the other lower bias and higher variance.  The\ndecision for one learning method vs. another is then not\nsimply a matter of selecting the one that reliably produces\ngood classifiers across training sets (small variance) or\nthe one that can learn classification\nproblems with very difficult decision boundaries (small bias).\nInstead, we have to weigh the respective\nmerits of bias and variance in our application and choose\naccordingly. This tradeoff is called the\n  bias-variance tradeoff .\n\n\nFigure 14.10  provides an illustration, which is\nsomewhat contrived, but will be useful as an example for the\ntradeoff. Some Chinese text contains English words written\nin the Roman alphabet like CPU, ONLINE, and\nGPS. Consider the task of distinguishing Chinese-only\nweb pages from mixed Chinese-English web pages. A search\nengine might offer Chinese users without knowledge of\nEnglish (but who understand loanwords like CPU) the\noption of filtering out mixed pages. We use two features for\nthis classification task: number of Roman alphabet\ncharacters and number of Chinese characters on the web\npage. As stated earlier, the distribution \n) of the generative\nmodel generates most mixed (respectively, Chinese) documents\nabove (respectively, below) the short-dashed line,\nbut there are a few noise documents.\n\n\nIn Figure 14.10 , we see three classifiers:\n\n\nOne-feature classifier. Shown as a dotted\nhorizontal line. This classifier\nuses\nonly one feature, the number of Roman alphabet\ncharacters. Assuming a learning method that minimizes the\nnumber of misclassifications in the training set, the\nposition of the horizontal decision boundary is not greatly\naffected by differences in the training set (e.g., noise\ndocuments). So a learning method producing this type of classifier has low variance. But its\nbias is high since it will consistently misclassify squares in the lower\nleft corner and ``solid circle'' documents with more than\n50 Roman characters.\n\nLinear classifier. Shown as a dashed line with\nlong dashes. Learning linear classifiers has less bias since \nonly  noise documents and possibly\na few documents close to the boundary between the two\nclasses are misclassified. The variance is higher than for the one-feature\nclassifiers, but still small: The dashed line with\nlong dashes deviates only slightly from the true boundary between\nthe two classes, and so will almost all linear decision boundaries learned\nfrom training sets. Thus, very few documents (documents\nclose to the class boundary) will be inconsistently\nclassified.\n\n``Fit-training-set-perfectly'' classifier. Shown as a\nsolid line. Here, the learning method constructs a decision boundary\nthat perfectly separates the classes in the training\nset. This method\nhas the lowest bias because there is no document that is\nconsistently misclassified - the classifiers sometimes even get\nnoise documents in the test set right. But the variance of\nthis learning method is high. Because noise documents can move the\ndecision boundary arbitrarily, test documents \nclose to noise documents in the\ntraining set\nwill be misclassified - something that a linear\nlearning method is unlikely  to do.\n\n\n\nIt is perhaps surprising that so many of the best-known text\nclassification algorithms are linear.\nSome of these methods, in particular linear SVMs, regularized\nlogistic regression and regularized linear regression, are\namong the most effective known methods.\nThe bias-variance tradeoff provides insight into their success.\nTypical classes in text classification are complex and seem\nunlikely to be modeled well linearly. However, this\nintuition is misleading for the high-dimensional spaces that we\ntypically encounter in text applications. With increased\ndimensionality, the likelihood of linear separability\nincreases rapidly\n(Exercise 14.8 ). Thus, linear\nmodels in high-dimensional spaces are quite powerful despite\ntheir linearity. Even more powerful nonlinear learning methods\ncan model decision boundaries that are more complex than a\nhyperplane, but they are also more sensitive to noise in the\ntraining data. Nonlinear learning methods\nsometimes perform better if the training set is large, but by no means\nin all cases.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: References and further reading\n Up: Vector space classification\n Previous: Classification with more than\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}