{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/combination-schemes-1.html",
  "title": "Combination schemes",
  "body": "\n\n\n\n\nCombination schemes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: References and further reading\n Up: Positional postings and phrase\n Previous: Positional index size.\n    Contents \n    Index\n\n\n\n\nCombination schemes\n\n\nThe strategies of biword indexes and positional indexes can be\nfruitfully combined.  If users commonly query on particular phrases,\nsuch as Michael Jackson, it is quite inefficient to keep merging\npositional postings lists.  A combination strategy uses a phrase index,\nor just a  biword index ,\nfor certain queries and uses a positional index\nfor other phrase queries.  Good queries to include in the phrase index\nare ones known to be common based on recent querying behavior.\nBut this is not the only criterion: the most expensive phrase queries\nto evaluate are ones where the individual words are common but the\ndesired phrase is comparatively rare.  Adding Britney Spears as a\nphrase index entry may only give a speedup factor to that query of about\n3, since most documents that mention either word are valid results,\nwhereas adding The Who as a phrase index entry may\nspeed up that query by a factor of 1000.  Hence, having the latter is\nmore desirable, even if it is a relatively less common query.\n\n\nWilliams et al. (2004) evaluate an even more\nsophisticated scheme which employs indexes of both these sorts and\nadditionally a partial next word index as a halfway house between the first\ntwo strategies.  For each term, a  next word index  records terms \nthat follow it in a document. They conclude that such a strategy allows a typical\nmixture of web phrase queries to be completed in one quarter of the time\ntaken by use of a positional index alone, while taking up 26% more\nspace than use of a positional index alone.\n\n\nExercises.\n\nAssume a biword index. Give an example of a document which will be returned for\na query of New York University but is actually a false positive which should not be returned.\n\n\n\nShown below is a portion of a positional index in the format:\nterm: doc1: position1, position2, ...; doc2: position1, position2, ...; etc.\n\nangels: 2: 36,174,252,651; 4: 12,22,102,432; 7: 17; \n\nfools: 2: 1,17,74,222; 4: 8,78,108,458; 7: 3,13,23,193; \n\nfear: 2: 87,704,722,901; 4: 13,43,113,433; 7: 18,328,528; \n\nin: 2: 3,37,76,444,851; 4: 10,20,110,470,500; 7: 5,15,25,195; \n\nrush: 2: 2,66,194,321,702; 4: 9,69,149,429,569; 7: 4,14,404; \n\nto: 2: 47,86,234,999; 4: 14,24,774,944; 7: 199,319,599,709; \n\ntread: 2: 57,94,333; 4: 15,35,155; 7: 20,320; \n\nwhere: 2: 67,124,393,1001; 4: 11,41,101,421,431; 7: 16,36,736;\n\n\nWhich document(s) if any match each of the following queries, where each\nexpression within\nquotes is a phrase query?\n\n\n``fools rush in''\n\n``fools rush in'' AND ``angels fear to tread''\n\n\n\n\nConsider the following fragment of a positional index with \nthe format: \n\nword: document: position, position, ; document: position, \n...\n\n\n\nGates: 1: 3; 2: 6; 3: 2,17; 4: 1;\n\nIBM: 4: 3; 7: 14; \n\nMicrosoft: 1: 1; 2: 1,21; 3: 3; 5: 16,22,51;\n\n\nThe / operator, word1 / word2 finds occurrences of \nword1 within  words of\nword2 (on either side), where  is a positive integer\nargument. Thus  demands that word1 be adjacent to \nword2.\n\n\nDescribe the set of documents that satisfy the query Gates /2\n  Microsoft.\n\nDescribe each set of values for  for which the query Gates /\n  Microsoft returns a different set of documents as the answer. \n\n\n\n\nConsider the general procedure for merging two \npositional postings lists for a given document, to determine the document positions \nwhere a document satisfies a / clause (in general there can be multiple positions\nat which each term occurs in a single\ndocument). We begin with a pointer to the \nposition of occurrence of each term and move each pointer along the list\nof occurrences in the document, checking as \nwe do so whether we have a hit for /. Each move of either pointer\ncounts as a step. Let  denote the total \nnumber of occurrences of the two terms in the document. What is the big-O\ncomplexity of the merge procedure, if we \nwish to have postings including positions in the result?\n\n\n\nConsider the adaptation of the basic algorithm for intersection of two postings\nlists postings-merge-algorithm to the one in \nFigure 2.12 (page ), which handles proximity\nqueries.\nA naive algorithm for this operation could be \n, where  \nis the sum of the lengths of the postings lists (i.e., the sum of document\nfrequencies) and  is the maximum length of a document (in tokens).\n\n\nGo through this algorithm carefully and explain how it works.\n\nWhat is the complexity of this algorithm?  Justify your answer carefully.\n\nFor certain queries and data distributions, would another algorithm be \nmore efficient?  What complexity does it have?\n\n\n\n\nSuppose we wish to use a postings intersection procedure \nto determine simply the list of documents that satisfy\na / clause, rather than returning the list of positions,\nas in Figure 2.12 (page ).\nFor simplicity, assume .\nLet  denote the total \nnumber of occurrences of the two terms in the document collection\n(i.e., the sum of their collection frequencies).\nWhich of the following is true? Justify your answer. \n\n\nThe merge can be accomplished in a number of steps linear in \nand independent of , and we can ensure that each \npointer moves only to the right.\n\nThe merge can be accomplished in a \nnumber of steps \nlinear in  and independent of , but a pointer may be forced to\nmove non-monotonically (i.e., to sometimes back up) \n\nThe merge can require  steps in some cases. \n\n\n\n\nHow could an IR system combine use of a positional index and use of stop words?\n\nWhat is the potential problem, and how could it be handled?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: References and further reading\n Up: Positional postings and phrase\n Previous: Positional index size.\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}