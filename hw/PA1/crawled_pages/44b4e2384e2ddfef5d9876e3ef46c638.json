{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/references-and-further-reading-2.html",
  "title": "References and further reading",
  "body": "\n\n\n\n\nReferences and further reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Dictionaries and tolerant retrieval\n Up: The term vocabulary and\n Previous: Combination schemes\n    Contents \n    Index\n\n\n\n \n\nReferences and further reading\n\n\nExhaustive discussion of the character-level processing of\n   can be found in Lunde (1998).  Character bigram\nindexes are perhaps the most standard approach to indexing Chinese,\nalthough some systems use word segmentation. Due to differences\nin the language and writing system, word segmentation is most usual\nfor Japanese (Luk and Kwok, 2002, Kishida et al., 2005).  The structure of a\ncharacter -gram index over unsegmented text differs\nfrom that in Section 3.2.2 (page ): there the -gram dictionary points to\npostings lists of entries in the regular dictionary, whereas here it\npoints directly to document postings lists.\nFor further discussion of Chinese word segmentation, see\nTseng et al. (2005), Sproat and Emerson (2003), Sproat et al. (1996), and\nGao et al. (2005).  \n\n\nLita et al. (2003) present a method for  truecasing .  Natural\nlanguage processing work on computational morphology is presented in\n(Sproat, 1992, Beesley and Karttunen, 2003). \n\n\n  Language identification  was perhaps\nfirst explored in cryptography; for example,\nKonheim (1981) presents a character-level -gram\nlanguage identification algorithm.  While other methods such as looking\nfor particular distinctive function words and letter combinations have\nbeen used, with the advent of widespread digital text, many people have\nexplored the character -gram technique, and found it to be highly\nsuccessful\n(Beesley, 1998, Dunning, 1994, Cavnar and Trenkle, 1994).\nWritten language identification is regarded as a fairly easy problem,\nwhile spoken language identification remains more difficult; see\nHughes et al. (2006) for a recent survey.\n\n\nExperiments on and discussion of the positive and negative impact of\n stemming  in English can be found in the following works:\nSalton (1989), Krovetz (1995), Hull (1996), Harman (1991). \nHollink et al. (2004) provide detailed results for the effectiveness of language-specific methods on 8 European languages. In terms of percent change in mean average precision (see page 8.4 ) over a baseline system, diacritic removal gains up to 23% (being especially helpful for Finnish, French, and Swedish). Stemming helped markedly for Finnish (30% improvement) and Spanish (10% improvement), but for most languages, including English, the gain from stemming was in the range 0-5%, and results from a lemmatizer were poorer still.  Compound splitting gained 25% for Swedish and 15% for German, but only 4% for Dutch.  Rather than language-particular methods, indexing character -grams (as we suggested for Chinese) could often give as good or better results: using within-word character 4-grams rather than words gave gains of 37% in Finnish, 27% in Swedish, and 20% in German, while even being slightly positive for other languages, such as Dutch, Spanish, and English.\nTomlinson (2003) presents broadly similar results.  Bar-Ilan and Gutman (2005) suggest that, at the time of their study (2003), the major commercial web search engines suffered from lacking decent language-particular processing; for example, a query on www.google.fr for l'électricité did not separate off the article l' but only matched pages with precisely this string of article+noun.\n\n\nThe classic presentation of    for IR can be found in Moffat and Zobel (1996).  Extended \ntechniques are discussed in Boldi and Vigna (2005).\nThe main paper in the algorithms literature is Pugh (1990), which\nuses multilevel skip pointers to give expected  list access\n(the same expected efficiency as using a tree data structure) with less\nimplementational complexity.\nIn practice, the effectiveness of using skip pointers depends on various\nsystem parameters.  Moffat and Zobel (1996) report conjunctive\nqueries running about five \ntimes faster with the use of skip pointers, but\nBahle et al. (2002, p. 217) report that, with modern CPUs, using skip lists\ninstead slows down search because it expands the size of the postings list\n(i.e., disk I/O dominates performance).  In contrast,\nStrohman and Croft (2007) again show good performance gains from\nskipping, in a system architecture designed to optimize for the large\nmemory spaces and multiple cores of recent CPUs.\n\n\nJohnson et al. (2006) report that 11.7% of all queries in two\n2002 web query logs contained  phrase queries , though\nKammenhuber et al. (2006) report only 3% phrase queries for a\ndifferent data set.  Silverstein et al. (1999) note that many\nqueries without explicit phrase operators are actually implicit phrase\nsearches.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Dictionaries and tolerant retrieval\n Up: The term vocabulary and\n Previous: Combination schemes\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}