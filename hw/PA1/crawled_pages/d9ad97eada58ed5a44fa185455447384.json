{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/markov-chains-1.html",
  "title": "Markov chains",
  "body": "\n\n\n\n\nMarkov chains\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Definition:\n Up: PageRank\n Previous: PageRank\n    Contents \n    Index\n\n\n\n\n \n\nMarkov chains\n \nA Markov chain is a discrete-time stochastic process: a process that occurs in a series of time-steps in each of which a random choice is made. A Markov chain consists of  states. Each web page will correspond to a state in the Markov chain we will formulate.\n\n\nA Markov chain is characterized by an  transition probability matrix  each of whose entries is in the interval ; the entries in each row of  add up to 1. The Markov chain can be in one of the  states at any given time-step; then, the entry  tells us the probability that the state at the next time-step is , conditioned on the current state being . Each entry  is known as a transition probability and depends only on the current state ; this is known as the Markov property. Thus, by the Markov property, \n\n\n\n\n\n(251)\n\n\nand\n\n\n\n\n\n\n(252)\n\n\nA matrix with non-negative entries that satisfies Equation 252 is known as a  stochastic matrix . A key property of a stochastic matrix is that it has a  principal left eigenvector  corresponding to its largest eigenvalue, which is 1.\n\n\nIn a Markov chain, the probability distribution of next states for a Markov chain depends only on the current state, and not on how the Markov chain arrived at the current state. Figure 21.2  shows a simple Markov chain with three states.  From the middle state A, we proceed with (equal) probabilities of 0.5 to either B or C.  From either B or C, we proceed with probability 1 to A.  The transition probability matrix of this Markov chain is then\n\n\n\n\n\n\n\n\n(253)\n\n\n\n\n\nFigure 21.2:\nA simple Markov chain with three states; the numbers on the links indicate the transition probabilities.\n\n\n\n\nA Markov chain's probability distribution over its states may be viewed as a  probability vector : a vector all of whose entries are in the interval , and the entries add up to 1. An -dimensional probability vector each of whose components corresponds to one of the  states of a Markov chain can be viewed as a probability distribution over its states.  For our simple Markov chain of Figure 21.2 , the probability vector would have 3 components that sum to 1.\n\n\nWe can view a random surfer on the web graph as a Markov chain, with one state for each web page, and each transition probability representing the probability of moving from one web page to another. The teleport operation contributes to these transition probabilities.  The adjacency matrix  of the web graph is defined as follows: if there is a hyperlink from page  to page , then , otherwise . We can readily derive the transition probability matrix  for our Markov chain from the  matrix :\n\n\nIf a row of  has no 1's, then replace each element by 1/N.  For all other rows proceed as follows.\n\nDivide each 1 in  by the number of 1's in its row.  Thus, if there is a row with three 1's, then each of them is replaced by .\n\nMultiply the resulting matrix by .\n\nAdd  to every entry of the resulting matrix, to obtain .\n\n\n\nWe can depict the probability distribution of the surfer's position at any time by a probability vector . At  the surfer may begin at a state whose corresponding entry in  is 1 while all others are zero. By definition, the surfer's distribution at  is given by the probability vector ; at  by \n, and so on. We will detail this process in Section 21.2.2 . We can thus compute the surfer's distribution over the states at any time, given only the initial distribution and the transition probability matrix .\n\n\nIf a Markov chain is allowed to run for many time steps, each state is visited at a (different) frequency that depends on the structure of the Markov chain. In our running analogy, the surfer visits certain web pages (say, popular news home pages) more often than other pages. We now make this intuition precise, establishing conditions under which such the visit frequency converges to fixed, steady-state quantity. Following this, we set the PageRank of each node  to this steady-state visit frequency and show how it can be computed.\n\n\n\n\nSubsections\n\n\nDefinition:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Definition:\n Up: PageRank\n Previous: PageRank\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}