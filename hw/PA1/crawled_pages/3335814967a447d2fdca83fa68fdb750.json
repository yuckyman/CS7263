{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/term-document-matrices-and-singular-value-decompositions-1.html",
  "title": "Term-document matrices and singular value decompositions",
  "body": "\n\n\n\n\nTerm-document matrices and singular value decompositions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Low-rank approximations\n Up: Matrix decompositions and latent\n Previous: Matrix decompositions\n    Contents \n    Index\n\n\n\n\n \n\nTerm-document matrices and singular value decompositions\n \nThe decompositions we have been studying thus far apply to square matrices. However, the matrix we are interested in is the \n term-document matrix  where (barring a rare coincidence) \n; furthermore,  is very unlikely to be symmetric. To this end we first describe an extension of the symmetric diagonal decomposition known as the  singular value decomposition . We then show in Section 18.3  how this can be used to construct an approximate version of .  It is beyond the scope of this book to develop a full treatment of the mathematics underlying singular value decompositions; following the statement of Theorem 18.2 we relate the singular value decomposition to the    from Section 18.1.1 .\nGiven , let  be the \n matrix whose columns are the orthogonal eigenvectors of \n, and  be the \n matrix whose columns are the orthogonal eigenvectors of \n.  Denote by  the transpose of a matrix .\n\n\nTheorem.\nLet  be the rank of the \n matrix . Then, there is a singular-value decomposition ( SVD  for short) of  of the form\n\n\n\n\n\n\n(232)\n\n\nwhere\n\n\nThe eigenvalues \n of \n are the same as the eigenvalues of \n;\n\nFor , let \n, with \n. Then the \n matrix  is composed by setting \n for , and zero otherwise.\n\n\nEnd theorem.\n\nThe values  are referred to as the singular values of .  It is instructive to examine the relationship of Theorem 18.2 to Theorem 18.1.1; we do this rather than derive the general proof of Theorem 18.2, which is beyond the scope of this book.\n\n\nBy multiplying Equation 232 by its transposed version, we have\n\n\n\n\n\n\n(233)\n\n\n\nNote now that in Equation 233, the left-hand side is a square symmetric matrix real-valued matrix, and the right-hand side represents its  symmetric diagonal decomposition  as in Theorem 18.1.1.  What does the left-hand side \n represent?  It is a square matrix with a row and a column corresponding to each of the  terms.  The entry  in the matrix is a measure of the overlap between the th and th terms, based on their co-occurrence in documents.  The precise mathematical meaning depends on the manner in which  is constructed based on term weighting.  Consider the case where  is the term-document  incidence matrix  of page 1.1 , illustrated in Figure 1.1 .  Then the entry  in \n is the number of documents in which both term  and term  occur.\n\n\n\n\n\n\nWhen writing down the numerical values of the SVD, it is conventional to represent  as an  matrix with the singular values on the diagonals, since all its entries outside this sub-matrix are zeros.  Accordingly, it is conventional to omit the rightmost  columns of  corresponding to these omitted rows of ; likewise the rightmost  columns of  are omitted since they correspond in  to the rows that will be multiplied by the  columns of zeros in .  This written form of the SVD is sometimes known as the  reduced SVD  or  truncated SVD  and we will encounter it again in Exercise 18.3 .  Henceforth, our numerical examples and exercises will use this reduced form.\n\n\nWorked example.\nWe now illustrate the singular-value decomposition of a  matrix of rank 2; the singular values are \n and .\n\n\n\n\n\n\n\n\n(234)\n\n\n\nEnd worked example.\n\nAs with the matrix decompositions defined in Section 18.1.1 , the singular value decomposition of a matrix can be computed by a variety of algorithms, many of which have been publicly available software implementations; pointers to these are given in Section 18.5 .\n\n\nExercises.\n\nLet \n\n\n\n\n\n(235)\n\n\nbe the term-document incidence matrix for a collection.  Compute the co-occurrence matrix \n.  What is the interpretation of the diagonal entries of \n when  is a term-document incidence matrix?\n\n\n\nVerify that the SVD of the matrix in Equation 235 is\n\n\n\n\n\n\n(236)\n\n\nby verifying all of the properties in the statement of Theorem 18.2.\n\n\n\nSuppose that  is a binary term-document incidence matrix.  What do the entries of \n represent?\n\n\n\nLet \n\n\n\n\n\n(237)\n\n\nbe a term-document matrix whose entries are term frequencies; thus term 1 occurs 2 times in document 2 and once in document 3.  Compute \n; observe that its entries are largest where two terms have their most frequent occurrences together in the same document.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Low-rank approximations\n Up: Matrix decompositions and latent\n Previous: Matrix decompositions\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}