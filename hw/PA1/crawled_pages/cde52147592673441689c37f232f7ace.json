{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/features-for-text-1.html",
  "title": "Features for text",
  "body": "\n\n\n\n\nFeatures for text\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Document zones in text\n Up: Improving classifier performance\n Previous: Large and difficult category\n    Contents \n    Index\n\n\n\n\nFeatures for text\n\n\nThe default in both ad hoc retrieval and text classification is to use\nterms as features.  However, for text classification, a great deal of\nmileage can be achieved by designing additional features which are\nsuited to a specific problem.  Unlike the case of IR query languages,\nsince these features are internal to the \nclassifier, there is no problem of communicating these features to an\nend user.  This process is generally referred to as  feature\nengineering .  At present, feature engineering remains a human craft,\nrather than something done by machine learning.  Good feature\nengineering can often markedly improve the performance of a text\nclassifier.  It is especially beneficial in some of the most important\napplications of text classification, like \n spam \nand  porn  filtering.\n\n\nClassification problems will often contain large numbers of terms\nwhich can be conveniently grouped, and which have a similar vote in\ntext classification problems.  Typical examples might be year mentions\nor strings of exclamation marks.  Or they may be more specialized\ntokens like ISBNs or chemical formulas.\nOften, using them directly in a classifier would greatly increase\nthe vocabulary without providing classificatory power beyond\nknowing that, say, a chemical formula is present.\nIn such cases,\nthe number of features and feature sparseness can be reduced by\nmatching such items with regular expressions and converting them into\ndistinguished tokens.  Consequently, effectiveness and classifier\nspeed are normally enhanced.\nSometimes all numbers are converted into a single feature, \nbut often some value can be had by distinguishing\ndifferent kinds of numbers, such as four digit numbers (which are\nusually years) versus other cardinal numbers versus real numbers with\na decimal point.  Similar techniques can be applied to dates, ISBN\nnumbers, sports game scores, and so on.\n\n\nGoing in the other direction, it is often useful to\nincrease the number of features by matching parts of words, and by\nmatching selected multiword patterns that are particularly\ndiscriminative.  Parts of words are often matched by character\n-gram features.  Such features can be particularly good at providing\nclassification clues for otherwise unknown words when the classifier\nis deployed.  For instance, an unknown word ending in -rase is\nlikely to be an enzyme, even if it wasn't seen in the training data.\nGood multiword patterns are often found by looking for distinctively\ncommon word pairs (perhaps using a mutual information criterion\nbetween words, in a similar way to its use in Section 13.5.1 (page )\nfor feature selection) and then using feature selection methods evaluated\nagainst classes.  They are useful when the components of a compound\nwould themselves be misleading as classification cues.  For instance,\nthis would be the case if the keyword ethnic was most\nindicative of the categories food and arts, the\nkeyword cleansing was most indicative of the category\nhome, but the collocation ethnic cleansing instead\nindicates the category world news.  Some text classifiers also\nmake use of features from named entity recognizers (cf. page 10 ). \n\n\nDo techniques like stemming and lowercasing (vocabulary) help\nfor text classification?  As always, the ultimate test is empirical\nevaluations conducted on an appropriate test collection.  But it is\nnevertheless useful to note that such techniques have a more\nrestricted chance of being useful for classification.  For IR, you\noften need to collapse forms of a word like oxygenate and\noxygenation, because the appearance of either in a document is\na good clue that the document will be relevant to a query about\noxygenation.  Given copious training\ndata, stemming necessarily delivers no value for text classification.\nIf several forms that stem together have a similar\nsignal, the parameters estimated for all of them will have similar\nweights.  Techniques like stemming help only in compensating for data\nsparseness.  This can be a useful role (as noted at the start of this\nsection), but often different forms of a word can convey significantly\ndifferent cues about the correct document classification.  Overly\naggressive stemming can easily degrade classification performance.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Document zones in text\n Up: Improving classifier performance\n Previous: Large and difficult category\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}