{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/dns-resolution-1.html",
  "title": "DNS resolution",
  "body": "\n\n\n\n\nDNS resolution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: The URL frontier\n Up: Crawling\n Previous: Distributing the crawler\n    Contents \n    Index\n\n\n\n\n \n\nDNS resolution\n \nEach web server (and indeed any host connected to the internet) has\na unique  IP address  in textual form, translating it to an IP address (in this case, 207.142.131.248) is a process known as  DNS resolution  or DNS lookup; here DNS stands for Domain Name Service. During DNS resolution, the program that wishes to perform this translation (in our case, a component of the web crawler) contacts a  DNS server  that returns the translated IP address. (In practice the entire translation may not occur at a single DNS server; rather, the DNS server contacted initially may recursively call upon other DNS servers to complete the translation.) For a more complex URL such as en.wikipedia.org/wiki/Domain_Name_System, the crawler component responsible for DNS resolution extracts the host name - in this case en.wikipedia.org - and looks up the IP address for the host en.wikipedia.org.\n\n\nDNS resolution is a well-known bottleneck in web crawling. Due to\nthe distributed nature of the Domain Name Service, DNS resolution\nmay entail multiple requests and round-trips across the internet,\nrequiring seconds and sometimes even longer. Right away, this puts\nin jeopardy our goal of fetching several hundred documents a second. A standard remedy is to introduce caching: URLs for which we have\nrecently performed DNS lookups are likely to be found in the DNS\ncache, avoiding the need to go to the DNS servers on the internet.\nHowever, obeying politeness constraints (see Section 20.2.3 ) limits the of cache hit rate.\n\n\nThere is another important difficulty in DNS resolution; the\nlookup implementations in standard libraries (likely to be used by\nanyone developing a crawler) are generally synchronous. This means\nthat once a request is made to the Domain Name Service, other\ncrawler threads at that node are blocked until the first request is completed. To circumvent this, most web crawlers implement their own DNS resolver as a component of the crawler. Thread  executing the resolver code sends a message to the DNS server and then performs a timed wait: it resumes either when being signaled by another thread or when a set time quantum expires. A single, separate DNS thread listens on the standard DNS port (port 53) for incoming response packets from the name service. Upon receiving a response, it signals the appropriate crawler thread (in this case, ) and hands it the response packet if  has not yet resumed because its time quantum has expired. A crawler thread that resumes because its wait time quantum has expired retries for a fixed number of attempts, sending out a new message to the DNS server and performing a timed wait each time; the designers of Mercator recommend of the order of five attempts. The time quantum of the wait increases exponentially with each of these attempts; Mercator started with one second and ended with roughly 90 seconds, in consideration of the fact that there are host names that take tens of seconds to resolve.\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: The URL frontier\n Up: Crawling\n Previous: Distributing the crawler\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}