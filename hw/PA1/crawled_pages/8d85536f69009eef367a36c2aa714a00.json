{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/other-languages-1.html",
  "title": "Other languages.",
  "body": "\n\n\n\n\nOther languages.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Stemming and lemmatization\n Up: Normalization (equivalence classing of\n Previous: Other issues in English.\n    Contents \n    Index\n\n\n\n\nOther languages.\n\n\nEnglish has maintained a dominant position on the WWW; approximately\n60% of web pages are in English (Gerrand, 2007).  But that\nstill leaves 40% of the web, and the non-English portion might be\nexpected to grow over time, since less than one third of Internet\nusers and less than 10% of the world's population primarily speak\nEnglish.  And there are signs of change: Sifry (2007) reports\nthat only about one third of blog posts are in English.\n\n\nOther languages again present distinctive issues in equivalence classing.\nThe French word for the has distinctive forms based not only on\nthe gender (masculine or feminine) and number of the following noun, but\nalso depending on whether the following word begins with a \nvowel: le, la, l', les.  \nWe may well wish to equivalence class these various forms of the.\nGerman has a convention whereby vowels with an umlaut can be rendered\ninstead as a two vowel digraph.  We would want to treat\nSchütze and Schuetze as equivalent.\n\n\n\n\nJapanese makes use of multiple intermingled writing systems\nand, like Chinese, does not segment words.\n  The text is mainly Chinese characters with the hiragana\n  syllabary for inflectional endings and function words.  The part in\n  latin letters is actually a Japanese \n  expression, but has been taken up as the name of an environmental\n  campaign by 2004 Nobel Peace Prize winner Wangari Maathai.  His name\n  is written using the katakana syllabary in the middle of the first\n  line.  The first four characters of the final line express a monetary\n  amount that we would want to match with ¥500,000 (500,000\n  Japanese yen).\n\n\n\nJapanese is a well-known difficult writing system, as illustrated in\nFigure 2.7 .  Modern Japanese is standardly an\nintermingling of multiple alphabets, principally Chinese characters, two\nsyllabaries (hiragana and katakana) and western characters (Latin\nletters, Arabic numerals, and various symbols).  While there are strong\nconventions and standardization through the education system over the\nchoice of writing \nsystem, in many cases the same word can be written with multiple writing\nsystems.  For example, a word may be written in katakana for emphasis\n(somewhat like italics).  Or a word may sometimes be written in hiragana\nand sometimes in Chinese characters.\nSuccessful retrieval thus requires complex equivalence classing across\nthe writing systems.  In particular, an end user might commonly present\na query entirely in hiragana, because it is easier to type, just as\nWestern end users commonly use all lowercase.\n\n\nDocument collections being indexed can include documents from many\ndifferent languages. \nOr a single document can easily contain text from \nmultiple languages.  For instance, a French email might quote clauses\nfrom a contract document written in English.\nMost commonly, the language is detected and language-particular\ntokenization and normalization rules are applied at a predetermined\ngranularity, such as whole documents or individual paragraphs, but this\nstill will not correctly deal with cases where language changes occur\nfor brief quotations. \nWhen document collections contain multiple languages, \na single index may have to \ncontain terms of several languages.  One option is to run a language\nidentification classifier on documents and then to tag terms in the\nvocabulary for their language.  Or this tagging can simply be omitted,\nsince it is relatively rare for the exact same character sequence to be a word\nin different languages. \n\n\nWhen dealing with foreign or complex words, particularly foreign\nnames, the spelling may be unclear or there may be variant\ntransliteration standards giving different spellings (for example,\nChebyshev and Tchebycheff or Beijing and\nPeking).  One way of dealing with this is to use heuristics to\nequivalence class or expand terms with phonetic equivalents.\nThe traditional and best known such algorithm is the Soundex algorithm,\nwhich we cover in Section 3.4 (page ).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Stemming and lemmatization\n Up: Normalization (equivalence classing of\n Previous: Other issues in English.\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}