{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/support-vector-machines-and-machine-learning-on-documents-1.html",
  "title": "Support vector machines and machine learning on documents",
  "body": "\n\n\n\n\nSupport vector machines and machine learning on documents\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Support vector machines: The\n Up: irbook\n Previous: Exercises\n    Contents \n    Index\n\n\n\n\n\nSupport vector machines and machine learning on documents\n\n\nImproving classifier effectiveness has been an area of intensive\nmachine-learning research over the last two decades, and this work has\nled to a new generation of state-of-the-art classifiers, such as support\nvector machines, boosted decision trees, regularized logistic\nregression, neural networks, and random forests.  Many of these methods,\nincluding support vector machines (SVMs), the main topic of this chapter, have\nbeen applied with success to information retrieval problems,\nparticularly text classification.  \nAn SVM\nis a kind\nof large-margin classifier: it is a\nvector space based machine learning method where the goal is\nto find a decision boundary between two classes that is \nmaximally far from any point\nin the training data (possibly discounting some points as outliers or noise).\n\n\nWe will initially motivate and\ndevelop SVMs for the case of two-class data sets that are separable by a\nlinear classifier \n(Section 15.1 ), and then extend the model in\nSection 15.2  to\nnon-separable data, multi-class problems, and nonlinear models,\nand also present some additional discussion of SVM performance.\nThe chapter then moves to consider the practical deployment of text\nclassifiers in Section 15.3 : what sorts of classifiers are\nappropriate when, and how can you exploit domain-specific text\nfeatures in classification?  Finally, we will consider how the machine\nlearning technology that we have been building for text classification\ncan be applied back to the problem of learning how to rank documents\nin ad hoc retrieval (Section 15.4 ). While several machine\nlearning methods have been applied to this task, use of SVMs has been\nprominent.    \nSupport vector machines are not necessarily better than other\nmachine learning methods (except perhaps in situations with little training data), but\nthey perform at the state-of-the-art level and have much current\ntheoretical and empirical appeal.  \n\n\n\n\nSubsections\n\nSupport vector machines: The linearly separable case\nExtensions to the SVM model\n\nSoft margin classification\nMulticlass SVMs\nNonlinear SVMs\nExperimental results\n\n\nIssues in the classification of text documents\n\nChoosing what kind of classifier to use\nImproving classifier performance\n\nLarge and difficult category taxonomies\nFeatures for text\nDocument zones in text classification\n\nUpweighting document zones.\nSeparate feature spaces for document zones.\nConnections to text summarization.\n\n\n\n\nMachine learning methods in ad hoc information retrieval\n\nA simple example of machine-learned scoring\nResult ranking by machine learning\n\n\nReferences and further reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Support vector machines: The\n Up: irbook\n Previous: Exercises\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}