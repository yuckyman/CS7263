{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/single-pass-in-memory-indexing-1.html",
  "title": "Single-pass in-memory indexing",
  "body": "\n\n\n\n\nSingle-pass in-memory indexing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Distributed indexing\n Up: Index construction\n Previous: Blocked sort-based indexing\n    Contents \n    Index\n\n\n\n\n \n\nSingle-pass in-memory indexing\n  Blocked sort-based indexing has excellent\nscaling properties, but it needs a data structure for\nmapping terms to termIDs. For very large collections, this\ndata structure does not fit into memory. A more scalable\nalternative is  single-pass in-memory indexing  or\n SPIMI . SPIMI uses terms\ninstead of termIDs, writes each block's dictionary to disk,\nand then starts a new dictionary for the next block. SPIMI\ncan index collections of any size as long as there is enough\ndisk space available.\n\n\n\n\nFigure 4.4:\nInversion of a block in \nsingle-pass in-memory indexing\n\n\n\n\nThe SPIMI algorithm is shown in Figure 4.4 .\nThe part of the algorithm that parses documents and\nturns them into a stream of term-docID pairs, which we call \ntokens here, has been omitted.  SPIMI-INVERT is called\nrepeatedly on the token stream until the entire\ncollection has been processed. \n\n\nTokens are processed one by\none (line 4)\n\n\nduring each successive call of SPIMI-INVERT. \nWhen a term occurs for the first time, it is added to the\ndictionary (best implemented as a hash), and a new\npostings list is created (line 6). The call in line 7\nreturns this postings list for subsequent occurrences of the\nterm.\n\n\nA difference between BSBI and SPIMI is that\nSPIMI adds a posting\ndirectly to its postings list (line 10). Instead of first collecting\nall termID-docID pairs and then sorting them (as we did in\nBSBI), each postings list is\ndynamic (i.e., its size is adjusted as it grows) and it\nis immediately available to collect postings. This has two advantages: It is faster because there\nis no sorting required, and it saves memory because we keep\ntrack of the term\na postings list belongs to, so the termIDs of postings need not\nbe stored. As a result, the blocks that individual calls of\nSPIMI-INVERT can process are much larger and the index\nconstruction process as a whole is more efficient.\n\n\nBecause we do not know how large the postings list of a term\nwill be when we first encounter it, we allocate space for a short\npostings list initially and double the space each time it is\nfull (lines 8-9). This means that some memory is wasted,\nwhich counteracts the memory savings from the omission of\ntermIDs in intermediate data structures. However, the\noverall memory requirements for the dynamically constructed\nindex of a block in SPIMI are still lower than in\nBSBI.\n\n\nWhen memory has been exhausted, we write the index of the\nblock (which consists of the dictionary and the postings lists)\nto disk (line 12). We have to sort the terms (line 11)\nbefore doing this because we want to \nwrite postings lists in lexicographic order to\nfacilitate the final merging step. If each block's postings\nlists were written in unsorted order, merging blocks\ncould not be accomplished by a simple linear scan through\neach block.\n\n\nEach call of SPIMI-INVERT writes a block to disk, just as in\nBSBI.  The last step of SPIMI\n(corresponding to line 7 in Figure 4.2 ; not shown in\nFigure 4.4 ) is then to merge the blocks into the\nfinal inverted index.\n\n\nIn addition to constructing a new dictionary structure for\neach block and eliminating the expensive sorting step, SPIMI\nhas a third important component: compression.  Both the\npostings and the dictionary terms\ncan be stored compactly on disk if we employ compression. Compression\nincreases the efficiency of the algorithm further because\nwe can process even larger blocks, and because the individual blocks\nrequire less space on disk. We refer readers\nto the literature for this aspect of the algorithm\n(Section 4.7 ).\n\n\nThe time complexity of SPIMI is  because no\nsorting of tokens is required and all operations are at most\nlinear in the size of the collection.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Distributed indexing\n Up: Index construction\n Previous: Blocked sort-based indexing\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}