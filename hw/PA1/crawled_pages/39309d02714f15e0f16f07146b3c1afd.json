{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/normalization-equivalence-classing-of-terms-1.html",
  "title": "Normalization (equivalence classing of terms)",
  "body": "\n\n\n\n\nNormalization (equivalence classing of terms)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Accents and diacritics.\n Up: Determining the vocabulary of\n Previous: Dropping common terms: stop\n    Contents \n    Index\n\n\n\n \n\nNormalization (equivalence classing of terms)\n\n\nHaving broken up our documents (and also our query)\ninto tokens, the easy case is if tokens in the query just match\ntokens in the token list of the document.  However, there are many cases\nwhen two character sequences are not quite the same but you would like a match\nto occur.\nFor instance, if you search for USA, you might hope to also match\ndocuments containing U.S.A. \n\n\n Token normalization  is the process of\ncanonicalizing tokens so that matches occur despite superficial\ndifferences in the character sequences of the tokens. \nThe most standard way to normalize is to implicitly create\n equivalence classes , which are \nnormally named after one member of the set.  For instance, if the\ntokens anti-discriminatory and antidiscriminatory are both\nmapped onto the term antidiscriminatory, in both the document\ntext and queries, then searches for one term will retrieve \ndocuments that contain either.  \n\n\nThe advantage of just using mapping rules that remove characters\nlike hyphens is that the equivalence classing to be done is implicit,\nrather than being fully calculated in advance: the terms that happen to\nbecome identical as the result of these rules are the equivalence\nclasses.   It is only easy to write rules of this sort that\nremove characters. Since the equivalence classes are implicit, it is not\nobvious when you might want to add characters.  For instance, it would be\nhard to know to turn antidiscriminatory into anti-discriminatory.\n\n\n\n\nFigure 2.6:\nAn example of how asymmetric expansion of query terms can\n  usefully model users' expectations.\n\n\n\n\nAn alternative to creating equivalence classes is to maintain\nrelations between unnormalized tokens.  This method can be extended to\nhand-constructed lists of synonyms such as car and\nautomobile, a topic we discuss further in Chapter 9 .\nThese term relationships can be achieved in two ways.\nThe usual way is to index unnormalized tokens and to maintain a query \nexpansion list of multiple vocabulary entries to consider for a certain\nquery term.  A query term is then effectively a disjunction of several\npostings lists.  The alternative is to perform the expansion during\nindex construction.  When the document contains automobile, we\nindex it under car as well (and, usually, also vice-versa).\nUse of either of these methods is considerably less efficient\nthan equivalence classing, as there are more postings to store and merge.\nThe first method adds a query expansion dictionary and requires more\nprocessing at query time, while the second method requires more space\nfor storing postings.  Traditionally, expanding the space\nrequired for the postings lists was seen as more disadvantageous, \nbut with modern storage costs, the increased flexibility that comes\nfrom distinct postings lists is appealing.\n\n\nThese approaches are more flexible than equivalence classes because the \nexpansion lists can overlap while not being identical.  This means\nthere can be an asymmetry in expansion.  An example of how such\nan asymmetry can be exploited is shown in Figure 2.6 :\nif the user enters windows, we wish to allow matches with the\ncapitalized Windows operating system, but this is not plausible\nif the user enters window, even though it is plausible for this\nquery to also match lowercase windows.\n\n\nThe best amount of equivalence classing or query expansion to do is a\nfairly open \nquestion.  Doing some\ndefinitely seems a good idea.  But doing a lot can easily have\nunexpected consequences of broadening queries in unintended ways.  For\ninstance, equivalence-classing U.S.A. and USA to the\nlatter by deleting periods from tokens might at first seem very\nreasonable, given the prevalent pattern of optional use of periods in\nacronyms.  However, if I put in as my query term C.A.T., I might\nbe rather upset if it matches every appearance of the word cat in\ndocuments.\n\nBelow we present some of the forms of\nnormalization that are commonly employed and how they are implemented.\nIn many cases they seem helpful, but they can also do harm.  In fact, you can\nworry about many details of \nequivalence classing, but it often turns out that providing processing\nis done consistently to the query and to documents, the fine details\nmay not have much aggregate effect on performance.\n\n\n\n\nSubsections\n\n\nAccents and diacritics.\nCapitalization/case-folding.\nOther issues in English.\nOther languages.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Accents and diacritics.\n Up: Determining the vocabulary of\n Previous: Dropping common terms: stop\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}