{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/book-organization-and-course-development-1.html",
  "title": "Book organization and course development",
  "body": "\n\n\n\n\nBook organization and course development\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Prerequisites\n Up: Preface\n Previous: Preface\n    Contents \n    Index\n\n\n\n\nBook organization and course development\n\n\nThis book is the result of a series of courses we have\ntaught at Stanford University and at the University of\nStuttgart, in a range of durations including a single\nquarter, one semester and two quarters.  These courses were\naimed at early-stage graduate students in computer science,\nbut we have also had enrollment from upper-class computer\nscience undergraduates, as well as students from law,\nmedical informatics, statistics, linguistics and various\nengineering disciplines.  The key design principle for this\nbook, therefore, was to cover what we believe to be\nimportant in a one-term graduate course on information\nretrieval.  An additional principle is to build each chapter\naround material that we believe can be covered in a single\nlecture of 75 to 90 minutes.\n\n\nThe first eight chapters of the book are devoted to the\nbasics of information retrieval, and in particular the heart\nof search engines; we consider this material to be core to\nany course on information retrieval.  Chapter 1 \nintroduces inverted indexes, and shows how simple Boolean\nqueries can be processed using such indexes.\nChapter 2  builds on this introduction by\ndetailing the manner in which documents are preprocessed\nbefore indexing and by discussing how inverted indexes are\naugmented in various ways for functionality and\nspeed. Chapter 3  discusses search structures for\ndictionaries and how to process queries that have spelling\nerrors and other imprecise matches to the vocabulary in the\ndocument collection being searched.\nChapter 4  describes a number of algorithms for\nconstructing the inverted index from a text collection with\nparticular attention to highly scalable and distributed\nalgorithms that can be applied to very large collections.\nChapter 5  covers techniques for compressing\ndictionaries and inverted indexes.\nThese techniques are critical\nfor achieving subsecond response times to user queries in\nlarge search engines.\nThe indexes and queries considered in\nintroicompress only deal with Boolean\nretrieval, in which a document either matches a query, or does\nnot. A desire to measure the extent to which a document\nmatches a query, or the score of a document for a query, motivates the development of term weighting and the\ncomputation of scores in Chapters 6 7 , leading\nto the idea of a list of documents that are rank-ordered for\na query.  Chapter 8  focuses on the evaluation of\nan information retrieval system based on the relevance of\nthe documents it retrieves, allowing us to compare the\nrelative performances of different systems on benchmark\ndocument collections and queries.\n\n\nqueryexpansionlink\nbuild on the foundation of the first eight chapters to cover\na variety of more advanced topics.\n  Chapter 9 \ndiscusses methods by which retrieval can be enhanced through\nthe use of techniques like relevance feedback and query\nexpansion, which aim at increasing the likelihood of\nretrieving relevant documents. Chapter 10  considers\ninformation retrieval from documents that are structured\nwith markup languages like XML and HTML. We treat structured\nretrieval by\nreducing it to the vector space scoring methods developed in\nChapter 6 .  Chapters 11 12  invoke\nprobability theory to compute scores for documents on\nqueries.  Chapter 11  develops traditional\nprobabilistic information retrieval, which provides a\nframework for computing the probability of relevance of a\ndocument, given a set of query terms. This probability may\nthen be used as a score in ranking.  Chapter 12 \nillustrates an alternative, wherein for each document in a\ncollection, we build a language model from which one can\nestimate a probability that the language model generates a\ngiven query.\n\n\nThis probability is another quantity with which we can rank-order\ndocuments.\n\n\nnbayeshierclust\ngive a treatment of various forms of machine learning and\nnumerical methods in\ninformation retrieval.  nbayessvm treat the\nproblem of classifying documents into a set of known\ncategories, given a set of documents along with the classes\nthey belong to.\nChapter 13  motivates statistical classification as one\nof the key technologies needed for a successful search\nengine, introduces Naive Bayes, a conceptually simple and\nefficient text classification method, and outlines the\nstandard methodology for evaluating text classifiers.\nChapter 14  employs\nthe vector space model from Chapter 6  and introduces\ntwo classification methods, Rocchio and kNN, that operate on document vectors.\nIt also presents the bias-variance tradeoff as an important\ncharacterization of learning problems that provides criteria\nfor\nselecting\nan appropriate method for a text classification problem.\nChapter 15  introduces support vector machines, which many\nresearchers currently view as the most effective text\nclassification method.\nWe also develop connections\nin this chapter between the problem of classification and seemingly disparate\ntopics such as the induction of scoring functions from a set\nof training examples.\n\n\nflatclust\nlsi\nconsider the problem of\ninducing clusters of related documents from a collection.\nIn Chapter 16 , we first give an overview of a number of\nimportant applications of clustering in information\nretrieval. We then describe two flat clustering algorithms: the  -means\nalgorithm, an efficient and widely used document clustering\nmethod; and the\nExpectation-Maximization algorithm, which is computationally\nmore expensive, but\nalso more flexible.\nChapter 17 \nmotivates the need for hierarchically structured clusterings\n(instead of flat clusterings) in many applications in\ninformation retrieval and\nintroduces a number of clustering\nalgorithms that produce a hierarchy of clusters. The chapter\nalso addresses the difficult problem of automatically\ncomputing labels for clusters.\n  Chapter 18  develops\nmethods from linear algebra that constitute an extension of\nclustering, and also offer intriguing prospects for\nalgebraic methods in information retrieval, which have been\npursued in the approach of latent semantic indexing.\n\n\nwebcharlink treat the problem of web search.  We give in Chapter 19  a summary of the basic challenges in web search, together with a set of techniques that are pervasive in web information retrieval.  Next, Chapter 20  describes the architecture and requirements of a basic web crawler.  Finally, Chapter 21  considers the power of link analysis in web search, using in the process several methods from linear algebra and advanced probability theory.\n\n\nThis book is not comprehensive in covering all topics\nrelated to information retrieval.  We have put aside a\nnumber of topics, which we deemed outside the scope of what\nwe wished to cover in an introduction to information\nretrieval class.  Nevertheless, for people interested in\nthese topics, we provide a few pointers to mainly textbook\ncoverage here.\n\n\n\nCross-language IR\n(Grossman and Frieder, 2004, ch. 4) and (Oard and Dorr, 1996).\n\n\n\nImage and Multimedia IR\n(Grossman and Frieder, 2004, ch. 4),\n(Baeza-Yates and Ribeiro-Neto, 1999, ch. 6),\n(Baeza-Yates and Ribeiro-Neto, 1999, ch. 11),\n(Baeza-Yates and Ribeiro-Neto, 1999, ch. 12),\n(del Bimbo, 1999),\n(Lew, 2001), and\n(Smeulders et al., 2000).\n\n\n\nSpeech retrieval\n(Coden et al., 2002).\n\n\n\nMusic Retrieval\n(Downie, 2006) and http://www.ismir.net/.\n\n\n\nUser interfaces for IR\n(Baeza-Yates and Ribeiro-Neto, 1999, ch. 10).\n\n\n\nParallel and Peer-to-Peer IR\n(Grossman and Frieder, 2004, ch. 7),\n(Baeza-Yates and Ribeiro-Neto, 1999, ch. 9), and (Aberer, 2001).\n\n\n\nDigital libraries\n(Baeza-Yates and Ribeiro-Neto, 1999, ch. 15) and (Lesk, 2004).\n\n\n\nInformation science perspective\n(Korfhage, 1997), (Meadow et al., 1999), and (Ingwersen and Järvelin, 2005).\n\n\n\nLogic-based approaches to IR\n(van Rijsbergen, 1989).\n\n\n\nNatural Language Processing techniques\n(Manning and Schütze, 1999), (Jurafsky and Martin, 2008), and (Lewis and Jones, 1996).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Prerequisites\n Up: Preface\n Previous: Preface\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}