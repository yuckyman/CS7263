{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/pseudo-relevance-feedback-1.html",
  "title": "Pseudo relevance feedback",
  "body": "\n\n\n\n\nPseudo relevance feedback\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Indirect relevance feedback\n Up: Relevance feedback and pseudo\n Previous: Evaluation of relevance feedback\n    Contents \n    Index\n\n\n\n \n\nPseudo relevance feedback\n\n\n Pseudo relevance feedback , also known\nas  blind relevance feedback ,\nprovides a method for automatic local analysis. It automates\nthe manual part of relevance feedback, so that the user gets improved\nretrieval performance without an extended interaction.\nThe method is to do normal retrieval to find an initial set of\nmost relevant documents, to then assume that the top  ranked\ndocuments are relevant, and finally to do relevance feedback as before\nunder this assumption.\n\n\n\n\n\n\nThis automatic technique mostly works. Evidence suggests\nthat it tends to work better than global analysis\n(Section 9.2 ). It has been found to improve\nperformance in the TREC ad hoc task. See for example the\nresults in Figure 9.5 . But it is not without the\ndangers of an automatic process. For example, if the query\nis about copper mines and the top several documents\nare all about mines in Chile, then there may be query drift\nin the direction of documents on Chile.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Indirect relevance feedback\n Up: Relevance feedback and pseudo\n Previous: Evaluation of relevance feedback\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}