{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/comparison-of-feature-selection-methods-1.html",
  "title": "Comparison of feature selection methods",
  "body": "\n\n\n\n\nComparison of feature selection methods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Evaluation of text classification\n Up: Feature selection\n Previous: Feature selection for multiple\n    Contents \n    Index\n\n\n\n\n \n\nComparison of feature selection methods\n \nMutual information and  represent rather different feature selection methods.\nThe independence of term  and class  can sometimes be\nrejected with high confidence even if \ncarries little information about membership of a document in . This\nis particularly true for rare terms. If a term occurs once\nin a large collection and that one occurrence is in the\npoultry class, then this is statistically\nsignificant. But a single occurrence\nis not very informative\naccording to the information-theoretic definition of information.\nBecause its criterion is significance, \nselects more rare terms (which are often less reliable\nindicators) than mutual information.\nBut the\nselection criterion of mutual information also does not\nnecessarily select the terms that maximize classification accuracy.\n\n\nDespite the differences between the two methods, the\nclassification accuracy of feature sets selected with\n and MI does not seem to differ systematically.\nIn most text classification problems, there are a few strong\nindicators and many weak indicators. As long as all strong\nindicators and a large number of weak indicators are\nselected, accuracy is expected to be good.\nBoth methods do this.\n\n\nFigure 13.8 \ncompares MI and  feature selection\nfor the multinomial model. Peak effectiveness is\nvirtually the same for both methods.  reaches this\npeak later, at 300 features, probably because the rare, but highly\nsignificant features it selects initially do not cover all\ndocuments in the class. However, features selected later (in\nthe range of 100-300) are of better quality than those\nselected by MI. \n\n\nAll three methods - MI,  and frequency based - are\n greedy methods. They may select features that\ncontribute no incremental information over previously selected\nfeatures. In Figure 13.7 , kong is selected\nas the seventh term even though it is highly correlated with\npreviously selected hong and therefore redundant.\nAlthough such redundancy can negatively impact accuracy,\nnon-greedy methods (see Section 13.7  for references)\nare rarely used in text classification due to their\ncomputational cost.\n\n\nExercises.\n\nConsider the following frequencies for the class\ncoffee for four terms in the first 100,000 documents\nof Reuters-RCV1:\n\n\n  \n \n \n \n \n term\n\n\n\n\n\n\n\n\n \n brazil\n98,012\n102\n1835\n51\n \n council\n96,322\n133\n3525\n20\n \n producers\n98,524\n119\n1118\n34\n \n roasted\n99,824\n143\n23\n10\n \n  \n \n \n \n \n\n\nSelect two of these four terms based on (i) ,\n(ii) mutual information, (iii)\nfrequency .\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Evaluation of text classification\n Up: Feature selection\n Previous: Feature selection for multiple\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}