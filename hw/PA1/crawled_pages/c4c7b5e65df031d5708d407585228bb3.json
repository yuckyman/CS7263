{
  "url": "http://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html",
  "title": "Multiclass SVMs",
  "body": "\n\n\n\n\nMulticlass SVMs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Nonlinear SVMs\n Up: Extensions to the SVM\n Previous: Soft margin classification\n    Contents \n    Index\n\n\n\n \n\nMulticlass SVMs\n\n\nSVMs are inherently two-class\nclassifiers.  The traditional way to do \nmulticlass classification with SVMs is to use one of the methods discussed in\nSection 14.5  (page 14.5 ).\nIn particular, the most common technique in practice has been to build \n one-versus-rest classifiers (commonly referred to as\n``one-versus-all'' or OVA classification), and to choose the class\nwhich classifies the test datum with greatest margin.  Another\nstrategy is to build a set of one-versus-one classifiers, and to\nchoose the class that is selected by the most classifiers.  While this\ninvolves building \n classifiers, the time for\ntraining classifiers may actually decrease, since the\ntraining data set for each classifier is much smaller.\n\n\nHowever, these are not very elegant approaches to solving multiclass\nproblems. \nA better alternative is provided by the construction of multiclass SVMs,\nwhere we build a two-class classifier over a feature vector\n\n derived\nfrom the pair consisting of the input features and the class of the datum.\nAt test time, the classifier chooses the class \n\n.  The margin\nduring training is the gap between this value for the\ncorrect class and for the nearest other class, and so the quadratic\nprogram formulation will require that \n\n.\nThis general method can be extended to give a multiclass formulation of\nvarious kinds of linear classifiers.  It is also a simple instance\nof a generalization of classification where the classes are not just\na set of independent, categorical labels, but may be arbitrary\nstructured objects with relationships defined between them.  In the\nSVM world, such work comes under the label of  structural SVMs .\nWe mention them again in Section 15.4.2 .\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Next: Nonlinear SVMs\n Up: Extensions to the SVM\n Previous: Soft margin classification\n    Contents \n    Index\n\n\n© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.\n2009-04-07\n\n\n\n"
}